{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab IS&A\n",
    "## Bagattin Enrico - Alessandro Doretto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Modules\n",
    "from utilities import *\n",
    "from dataPreparation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "years = [2017, 2018, 2019, 2020]\n",
    "yearsForFeatures = [2016, 2017, 2018, 2019, 2020]\n",
    "paths = []\n",
    "for y in years:\n",
    "    paths.append('matches/' + str(y) + '.xlsx') \n",
    "availablePaths = list(glob.glob(\"matches/20*.xlsx\"))\n",
    "matches = [pd.read_excel(path) for path in paths]\n",
    "yearZeroForFeatures = pd.read_excel('matches/' + str(years[0]-1) + '.xlsx')\n",
    "# TODO: Load matches based on number of past years choosen\n",
    "df = pd.concat(matches, ignore_index=True, sort=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.describe(include='all', percentiles=[]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cleaning and preparing data\n",
    "\n",
    "## Remove Winner/Loser reference\n",
    "All the column with Winner/Loser reference will be substituted by Player0/Player1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = removeWinnerLoserReference(df)\n",
    "yearZeroForFeatures = removeWinnerLoserReference(yearZeroForFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling null:\n",
    "* Rank: take the max rank plus one\n",
    "* Pts: set default zero\t\n",
    "* Avg odd: take mode of matches with same (or similar) players rank\n",
    "* B365, PS: fill with avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rankDefault = max(df['Rank0'].max(), df['Rank1'].max())+1\n",
    "df.fillna({'Rank0': rankDefault, 'Rank1': rankDefault, 'Pts0': 0, 'Pts1': 0}, inplace=True)\n",
    "\n",
    "nullOddsDf = df[df[['B3650', 'B3651', 'PS0', 'PS1', 'Avg0', 'Avg1']].isna().any(axis=1)]\n",
    "for index, row in nullOddsDf.iterrows():\n",
    "    if pd.isnull(row['Avg0']) or pd.isnull(row['Avg1']):\n",
    "        Avg0, Avg1 = findOddsForRow(row, df.dropna(subset=['Avg0', 'Avg1']))\n",
    "        df.at[index, 'Avg0'] = row['Avg0'] = Avg0\n",
    "        df.at[index, 'Avg1'] = row['Avg1'] = Avg1\n",
    "    if pd.isnull(row['B3650']):\n",
    "        df.at[index, 'B3650'] = row['Avg0']\n",
    "    if pd.isnull(row['B3651']):\n",
    "        df.at[index, 'B3651'] = row['Avg1']\n",
    "    if pd.isnull(row['PS0']):\n",
    "        df.at[index, 'PS0'] = row['Avg0']\n",
    "    if pd.isnull(row['PS1']):\n",
    "        df.at[index, 'PS1'] = row['Avg1']\n",
    "\n",
    "df.dropna(subset=['Avg0', 'Avg1'], inplace=True) # Drop rows that hasn't similar rank matches\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Round ????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# X['Round'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# you might change this according to a notion of weight\n",
    "# X['Round'] = X['Round'].map ({  '1st Round'    : 1, \n",
    "#                                 '2nd Round'    : 2, \n",
    "#                                 '3rd Round'    : 4,\n",
    "#                                 '4th Round'    : 8,\n",
    "#                                 'Quarterfinals': 16,\n",
    "#                                 'Round Robin'  : 32,\n",
    "#                                 'Semifinals'   : 32,\n",
    "#                                 'The Final'    : 64})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features\n",
    "* [Elo rating](https://en.wikipedia.org/wiki/Elo_rating_system): a method for calculating the relative skill levels of players in zero-sum games\n",
    "* Number of matches played during the last year\n",
    "* Percentage of matches won during the last year\n",
    "* Injuries: number matches in witch the player retired or walkover in the past year \n",
    "* Winning streak: current sequence of won games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = addEloRatingFeature(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = addMatchesPlayedAndWonFeatures(X, yearZeroForFeatures, yearsForFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = addInjuriesAndWinningStreakFeatures(X, yearZeroForFeatures, yearsForFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.to_csv('generated/beforeDuplication.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row duplication\n",
    "To use both match outcomes for our prediction models we will duplicate each row. We can do it by switching all the player features for each duplicated row and adding a Winner column for the match result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "duplication = X.copy()\n",
    "duplication.columns = ['Date', 'Location', 'Tournament', 'Series', 'Court', 'Surface', 'Round',\n",
    "       'Player1', 'Player0', 'Rank1', 'Rank0', 'Pts1', 'Pts0', 'Comment',\n",
    "       'B3651', 'B3650', 'PS1', 'PS0', 'Avg1', 'Avg0', 'EloRating1',\n",
    "       'EloRating0', 'MatchesPlayed1', 'MatchesPlayed0', 'MatchesWon1',\n",
    "       'MatchesWon0', 'Injuries1', 'Injuries0', 'WinningStreak1',\n",
    "       'WinningStreak0']\n",
    "\n",
    "# Add the winner column\n",
    "X = X.assign(Winner=np.zeros(X.shape[0])) # Player 0 always win\n",
    "duplication = duplication.assign(Winner=np.ones(X.shape[0])) # Player 1 always win\n",
    "\n",
    "X = pd.concat([X, duplication])\n",
    "X.reset_index(inplace=True)\n",
    "X.sort_values(by='index', inplace=True)\n",
    "X.drop(columns=['Date', 'Comment', 'index'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding\n",
    "* Location\n",
    "* Tournament\n",
    "* Series\n",
    "* Court\n",
    "* Surface\n",
    "* Round\n",
    "* Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "print('Total number of columns:', len(X.columns))\n",
    "\n",
    "X.to_csv('generated/finalDataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset subdivision: Train, Validation, Test\n",
    "\n",
    "Train 60%, Validation 20%, Test 20% (taking as test the last part of the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv('generated/finalDataset.csv')\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = X.Winner.values\n",
    "X.drop(columns='Winner', inplace=True)\n",
    "\n",
    "test_size = len(X)//5\n",
    "X_test     = X[-test_size:]\n",
    "y_test     = y[-test_size:]\n",
    "X_train_80 = X[:-test_size]\n",
    "y_train_80 = y[:-test_size]\n",
    "\n",
    "# Random split for training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_80, y_train_80, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction models\n",
    "We start by calculating how much powerful are the bookmakers' alghoritms, then we create and tune ours, let's see the results\n",
    "## Baseline\n",
    "Our first goal is to beat the average bookmaker accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.46 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Player 1 wins if the odd is smaller than player 0\n",
    "baseline = X_test['Avg1'] < X_test['Avg0']\n",
    "baseline = baseline.astype(int)\n",
    "baseline_test_acc = accuracy_score(y_true=y_test, y_pred=baseline)\n",
    "print (\"Test Accuracy: {:.2f}\".format(baseline_test_acc*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuraciesForModels = {'kNN': [], 'Naive Bayes': [], 'Decision Tree': [], 'Random Forest': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest-Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_train = scaler.transform(X_train)\n",
    "scaled_valid = scaler.transform(X_valid)\n",
    "scaled_train_80 = scaler.transform(X_train_80)\n",
    "scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: kNN is very slow with this dataset\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for k in range(1,16):\n",
    "    kNN = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    kNN.fit(scaled_train, y_train)\n",
    "    y_pred = kNN.predict(scaled_valid)\n",
    "    valid_acc = accuracy_score(y_true=y_valid, y_pred=y_pred)\n",
    "    print (\"k: {:2d} | Validation Accuracy: {:.3f}\".format(k, valid_acc))\n",
    "    accuracies += [[valid_acc, k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the resulting accuracies for a faster running process purpose\n",
    "\n",
    "accuracies =  [[0.5272562083585706, 1],\n",
    "                [0.5399757722592369, 2],\n",
    "                [0.5590551181102362, 3],\n",
    "                [0.5632949727437916, 4],\n",
    "                [0.5793458509993943, 5],\n",
    "                [0.5838885523924894, 6],\n",
    "                [0.5990308903694731, 7],\n",
    "                [0.5896426408237432, 8],\n",
    "                [0.6005451241671714, 9],\n",
    "                [0.595396729254997, 10],\n",
    "                [0.6053906723198061, 11],\n",
    "                [0.5993337371290127, 12],\n",
    "                [0.6035735917625682, 13],\n",
    "                [0.5999394306480921, 14],\n",
    "                [0.6078134463961236, 15]]\n",
    "\n",
    "accuraciesForModels['kNN'] = accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy, best_k = max(accuracies)\n",
    "print ( \"Best K\", best_k )\n",
    "\n",
    "# here we are using both training and validation,\n",
    "# to exploit the most data\n",
    "\n",
    "kNN = neighbors.KNeighborsClassifier(n_neighbors=best_k)\n",
    "kNN.fit(scaled_train_80, y_train_80)\n",
    "\n",
    "# Finally evaluate on test\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=kNN.predict(scaled_test))\n",
    "print (\"Test Accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.852 - Validation Accuracy: 0.816\n",
      "Test Accuracy: 0.815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# train and predict\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# compute Accuracy\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=gnb.predict(X_train))\n",
    "valid_acc = accuracy_score(y_true=y_valid, y_pred=gnb.predict(X_valid))\n",
    "print (\"Train Accuracy: {:.3f} - Validation Accuracy: {:.3f}\".format(train_acc, valid_acc))\n",
    "\n",
    "gnb.fit(X_train_80,y_train_80)\n",
    "\n",
    "# Finally evaluate on test\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=gnb.predict(X_test))\n",
    "print (\"Test Accuracy: {:.3f}\".format(test_acc))\n",
    "\n",
    "accuraciesForModels['Naive Bayes'] = [[valid_acc, 50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaves:  5 - Train Accuracy: 0.852 - Validation Accuracy: 0.854\n",
      "Leaves: 10 - Train Accuracy: 0.852 - Validation Accuracy: 0.854\n",
      "Leaves: 15 - Train Accuracy: 0.854 - Validation Accuracy: 0.854\n",
      "Leaves: 20 - Train Accuracy: 0.859 - Validation Accuracy: 0.848\n",
      "Leaves: 25 - Train Accuracy: 0.861 - Validation Accuracy: 0.848\n",
      "Leaves: 30 - Train Accuracy: 0.862 - Validation Accuracy: 0.846\n",
      "Leaves: 35 - Train Accuracy: 0.864 - Validation Accuracy: 0.846\n",
      "Leaves: 40 - Train Accuracy: 0.866 - Validation Accuracy: 0.845\n",
      "Leaves: 45 - Train Accuracy: 0.867 - Validation Accuracy: 0.845\n",
      "Leaves: 50 - Train Accuracy: 0.868 - Validation Accuracy: 0.845\n",
      "Leaves: 55 - Train Accuracy: 0.872 - Validation Accuracy: 0.845\n",
      "Leaves: 60 - Train Accuracy: 0.875 - Validation Accuracy: 0.844\n",
      "Leaves: 65 - Train Accuracy: 0.876 - Validation Accuracy: 0.844\n",
      "Leaves: 70 - Train Accuracy: 0.879 - Validation Accuracy: 0.844\n",
      "Leaves: 75 - Train Accuracy: 0.880 - Validation Accuracy: 0.843\n",
      "Leaves: 80 - Train Accuracy: 0.881 - Validation Accuracy: 0.842\n",
      "Leaves: 85 - Train Accuracy: 0.883 - Validation Accuracy: 0.841\n",
      "Leaves: 90 - Train Accuracy: 0.886 - Validation Accuracy: 0.839\n",
      "Leaves: 95 - Train Accuracy: 0.889 - Validation Accuracy: 0.839\n",
      "Leaves: 100 - Train Accuracy: 0.890 - Validation Accuracy: 0.839\n",
      "Best Max Leaves 10\n",
      "Test Accuracy: 0.852\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for max_leaves in range(5, 101, 5):\n",
    "    # train and predict\n",
    "    dt = tree.DecisionTreeClassifier(max_leaf_nodes=max_leaves)\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    # compute Accuracy\n",
    "    train_acc = accuracy_score(y_true=y_train, y_pred=dt.predict(X_train))\n",
    "    valid_acc = accuracy_score(y_true=y_valid, y_pred=dt.predict(X_valid))\n",
    "    print (\"Leaves: {:2d} - Train Accuracy: {:.3f} - Validation Accuracy: {:.3f}\".format(\n",
    "        max_leaves,  train_acc, valid_acc) )\n",
    "    \n",
    "    accuracies += [ [valid_acc, max_leaves] ]\n",
    "\n",
    "best_accuracy, best_max_leaves = max(accuracies)\n",
    "print ( \"Best Max Leaves\", best_max_leaves )\n",
    "\n",
    "# here we are using both training and validation,\n",
    "# to exploit the most data\n",
    "dt = tree.DecisionTreeClassifier(max_leaf_nodes=best_max_leaves)\n",
    "dt.fit(X_train_80,y_train_80)\n",
    "\n",
    "# Finally evaluate on test\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=dt.predict(X_test))\n",
    "print (\"Test Accuracy: {:.3f}\".format(test_acc))\n",
    "\n",
    "accuraciesForModels['Decision Tree'] = accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators:  1 - Train Accuracy: 0.897 - Validation Accuracy: 0.724\n",
      "Estimators:  5 - Train Accuracy: 0.981 - Validation Accuracy: 0.816\n",
      "Estimators:  9 - Train Accuracy: 0.993 - Validation Accuracy: 0.816\n",
      "Estimators: 13 - Train Accuracy: 0.997 - Validation Accuracy: 0.838\n",
      "Estimators: 17 - Train Accuracy: 0.997 - Validation Accuracy: 0.843\n",
      "Estimators: 21 - Train Accuracy: 0.998 - Validation Accuracy: 0.842\n",
      "Estimators: 25 - Train Accuracy: 0.999 - Validation Accuracy: 0.844\n",
      "Estimators: 29 - Train Accuracy: 0.999 - Validation Accuracy: 0.846\n",
      "Estimators: 33 - Train Accuracy: 0.999 - Validation Accuracy: 0.848\n",
      "Estimators: 37 - Train Accuracy: 1.000 - Validation Accuracy: 0.847\n",
      "Estimators: 41 - Train Accuracy: 1.000 - Validation Accuracy: 0.843\n",
      "Estimators: 45 - Train Accuracy: 1.000 - Validation Accuracy: 0.842\n",
      "Estimators: 49 - Train Accuracy: 1.000 - Validation Accuracy: 0.849\n",
      "Best Estimators 49\n",
      "Test Accuracy: 0.844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for estimators in range(1, 50, 4):\n",
    "    # train a decision tree classifier\n",
    "    rf = RandomForestClassifier(n_estimators=estimators)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # compute Accuracy\n",
    "    train_acc = accuracy_score(y_true=y_train, y_pred=rf.predict(X_train))\n",
    "    valid_acc = accuracy_score(y_true=y_valid, y_pred=rf.predict(X_valid))\n",
    "    print (\"Number of Trees: {:2d} - Train Accuracy: {:.3f} - Validation Accuracy: {:.3f}\".format(\n",
    "        estimators,  train_acc, valid_acc) )\n",
    "    \n",
    "    accuracies += [ [valid_acc, estimators] ]\n",
    "\n",
    "best_accuracy, best_estimators = max(accuracies)\n",
    "print ( \"Best Number of Trees\", best_estimators )\n",
    "\n",
    "# here we are using both training and validation,\n",
    "# to exploit the most data\n",
    "rf = tree.DecisionTreeClassifier(max_leaf_nodes=best_estimators)\n",
    "rf.fit(X_train_80,y_train_80)\n",
    "\n",
    "# Finally evaluate on test\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=rf.predict(X_test))\n",
    "print (\"Test Accuracy: {:.3f}\".format(test_acc))\n",
    "\n",
    "accuraciesForModels['Random Forest'] = accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Results\n",
    "Let's visualize all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.539976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kNN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.559055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kNN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.563295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN</td>\n",
       "      <td>5</td>\n",
       "      <td>0.579346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Parameter  Accuracy\n",
       "0   kNN         1  0.527256\n",
       "1   kNN         2  0.539976\n",
       "2   kNN         3  0.559055\n",
       "3   kNN         4  0.563295\n",
       "4   kNN         5  0.579346"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Model', 'Parameter', 'Accuracy']\n",
    "accuraciesForPlots = pd.DataFrame(columns = cols)\n",
    "\n",
    "for i, key in enumerate(accuraciesForModels):\n",
    "    for el in accuraciesForModels[key]:\n",
    "        accuraciesForPlots.loc[len(accuraciesForPlots)] = [key, el[1], el[0]]\n",
    "\n",
    "accuraciesForPlots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAAGWCAYAAAB/3sLLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nOzdeVxU9f7H8fcMq4qIGGBpprl2S9NbuS+peRUEcatMza28VrdF29DSNE1N7UqLZWV1f9bVXLJSysyrppl4Lbvllm2mKSogoqLIPt/fH6OjCAgMDCPwej4ePGbOMmc+56DnO2++53zHYowxAgAAAAAUm9XdBQAAAABAeUWgAgAAAAAnEagAAAAAwEkEKgAAAABwEoEKAAAAAJxEoAIAAAAAJxGoACfExcWpadOmGjJkSJ5lEyZMUNOmTZWcnFysbY4ZM0Yff/zxZdfZtm2bwsPDi7XdS3Xr1k27du3KM//ee+/V0KFDZbPZHPOSk5PVtGlTSRf2efny5ble9+6772r8+PElqgkAyqPy3BYUds6/nFdeeUWffvppid7/4jq6deumyMhI9enTR6GhoZo3b16pbBsoKwQqwEk+Pj46cOCADh8+7Jh39uxZff/9926sqmR27NihN998s8DlVqtVs2bN0v79+8uwKgC4cpXntqCwc35BHnvsMfXt27fU6nj66ae1cuVKrVq1SkuXLtWSJUvKxfEDziNQAU7y8PBQaGioYmJiHPPWrl2r7t2751pv6dKlCg8PV58+fTRq1ChHGElISNDIkSPVu3dvjR49WseOHXO8Zt++fRo1apT69++vyMhIffTRR5etJTY2VpGRkXl+Nm/eXOBrUlNTNWTIEM2ZM8cx76GHHtJ7772nH3/8Md/X+Pr6auTIkXriiSeUmZl52ZoAoDIoz23B5c75NptNL7zwgu68806FhYUpNDTUEXLGjx+vd999V0uXLtWYMWNy1dupUyfl5OQUu/bzUlNTJUk1a9aUJH311VcaNGiQ+vfvr9tvv10vv/yyJGnixImaO3eu43WrVq3SP/7xD0nShg0bdOedd6pv374aNGiQfvjhB0d957fVr18/LVq0qEg1AYUyAIrt0KFDpmXLlmbXrl0mNDTUMX/48OHml19+MU2aNDHHjx83sbGx5o477jDHjx83xhizYsUKExoaamw2m3nooYdMdHS0McaYAwcOmJYtW5oVK1aYrKwsExYWZnbv3m2MMSYlJcWEhoaaH374wfz3v/81vXv3LlHtXbt2NbGxsebuu+82b731lmP+0KFDzRdffGGWLl1qunfvbk6fPm2OHz9umjRpkmufc3JyzODBg82LL75ojDHmnXfeMVFRUSWqCQDKo/LcFhR2zv/f//5nHnnkEZOTk2OMMeatt94yY8aMMcYYExUVZd555x1z+vRpc8stt5jExERjjDGzZ882c+fOvWzt+dXRtWtX06dPHxMWFmZuvPFG89RTTxmbzWZsNpsZOnSo2b9/vzHGmPj4eHPDDTeY48ePm59++sl06NDBZGVlGWOMGTx4sPn666/N/v37TXh4uElOTjbGGPPrr7+aDh06mNTUVDNhwgRHu5eYmGjGjh3r2D+gJDzdHeiA8uymm26S1WrV7t27VatWLaWmpqpJkyaO5Zs3b1ZYWJgCAwMlSf3799f06dMVFxen2NhYRUVFSZKuu+46tWnTRpJ04MABHTx4UM8884xjO+np6frpp5/UsGHDfOuIjY3VrFmz8sx/8skn1alTpzzzn3rqKXl6emrYsGF5lt1111365ptvNGXKlFw1nGe1WjVnzhz169dPHTt2vNzhAYBKoby2BVLB5/xWrVqpRo0aWrJkiQ4dOqRt27apWrVquV7r5+ennj17atWqVRoxYoRWrVqlxYsXX7b2li1b5qnh6aefVq9evSRJp06d0kMPPaS3335bY8aM0ZtvvqmNGzfqs88+0759+2SMUVpamm644QbVrVtXGzduVIMGDZSYmKiOHTtq8eLFSkxM1IgRIxzbt1gsOnjwoHr06KGoqCjt3LlT7dq108SJE2W1crEWSo5ABZRQnz59tGrVKgUGBioyMjLXMmNMnvWNMcrOzpbFYsm13NPT/t8xJydH/v7+WrlypWNZUlKSqlevXuCleO3bt8+1fmEefPBBbdu2TXPmzNGkSZPyLJ82bZpjv/JzzTXXaMqUKYqKiirV6+gBoLwqj23Befmd8zdu3Kjp06dr5MiR6t69u66//vp824Q777xTkyZNUsOGDdWoUSNde+21+uWXXwqsvTA1atRQWFiYvvrqK917773q16+f7rjjDt16660aMGCA1q1b5zheQ4YM0YoVK1S/fn3dddddslgsstlsateunePSQEk6evSogoOD1axZM3355ZeKjY3V1q1b9frrr2vJkiWqV69esY8ZcDFiOVBCkZGRWrNmjVavXp1n1KWOHTtq9erVjlGeVqxYoYCAAF133XXq1KmTli5dKkk6cuSItm3bJklq0KCBfHx8HA3R0aNHFR4ert27d5dazS1atNCUKVO0Zs0affPNN3mW16hRQ3PmzFF0dHSB2wgNDVXnzp21cOHCUqsLAMqr8tgWnJffOX/Lli3q2rWrBg8erObNm2vdunXKycnJ89rzPU6vv/667rzzzhLXnpWVpY0bN6pFixb6888/debMGY0dO1bdunXTt99+q8zMTMfIhD179tTevXu1du1aDRgwQJLUtm1bbdmyRfv27ZMkbdq0SX369FFGRoaeeOIJrV69Wr1799bkyZPl5+eno0ePluDIAXb0UAElFBISooYNG6p69eoKCAjItaxDhw4aMWKEhg8fLpvNpsDAQL311luyWq2aPHmyJkyYoNDQUNWuXVvNmjWTJHl7e+uNN97Q9OnT9c477yg7O1uPPfaYbrnlFkdDWxoCAwM1efJkPfPMM7lupj6vdevWGjFixGVHgJo4cSIjMQGAym9bcN6l5/xBgwbpySefVEREhDw8PHTrrbdq7dq1uYZZP+/OO+/UG2+8oTvuuKPQ2vMze/ZszZ8/XxaLRWlpaWrbtq0eeOABeXp66vbbb1doaKj8/f1Vr149NWrUSH/++afq1asnb29v9ezZU0lJSY7LKRs3bqypU6fq8ccflzFGnp6emj9/vqpWraqHHnpIzz77rJYuXSoPDw/dcccdat26dakfS1Q+FpNfPzQAAABwBTt79qyGDh2qyZMn6+abb3Z3OajEuOQPAAAA5crmzZt1++23q02bNoQpuJ3Le6jOnDmjQYMG6c0331TdunVzLdu7d68mTpyoM2fO6NZbb9Xzzz/vuBkTAAAAAK50Lu2h2rFjh+655x4dOHAg3+VPPfWUJk2apC+//FLGGC1btsyV5QAAAABAqXJpoFq2bJkmT56s4ODgPMsOHz6s9PR0x+gw/fv315o1a1xZDgAAAACUKpdeXzd9+vQClyUmJiooKMgxHRQUpISEhDzrpaSkKCUlJde8nJwcpaWlqVGjRlwiCABwGm0MAKCk3NZS5HfrlsViyTNv4cKFmjdvXr7bWL9+fZ77sgAAKCraGABASbktUIWEhCgpKckxfezYsXwvDRw+fLj69euXa158fLyGDBni8hoBABUbbQwAoKTcFqjq1KkjHx8fff/997rlllv06aefqnPnznnW8/f3l7+/vxsqBABUdLQxAICSKvPvoRo9erR27dolSXrppZc0c+ZMhYaGKi0tTcOGDSvrcgAAAADAaWXSQ7VhwwbH8wULFjieN2vWTB999FFZlAAAAAAApa7Me6gAAAAAoKIgUAEAAACAkwhUAAAAAOAkAhUAAAAAOIlABQAAAABOIlABAAAAgJMIVAAAAADgJAIVAAAAADiJQAUAAAAATiJQAQAAAICTCFQAAAAA4CQCFQAAAAA4iUAFAAAAAE4iUAEAAACAkwhUAAAAAOAkAhUAAAAAOIlABQAAAABOIlABAAAAgJMIVAAAAADgJAIVAAAAADiJQAUAAAAATiJQAQAAAICTXBqoYmJiFBYWph49emjRokV5lm/atEkRERGKiIjQE088odTUVFeWAwAAAAClymWBKiEhQdHR0Vq8eLFWrlyppUuX6vfff3csT0lJ0fjx4xUdHa2YmBg1a9ZM0dHRrioHAAAAAEqdywJVbGys2rZtq4CAAFWtWlU9e/bUmjVrHMsPHDiga665Ro0aNZIkde3aVevWrXNVOQAAAABQ6jxdteHExEQFBQU5poODg7Vz507HdP369RUfH6+ff/5ZzZo10xdffKGkpKQ820lJSVFKSkquefHx8a4qGwBQidDGAABKymWByhiTZ57FYnE89/f316xZszRp0iTZbDbddddd8vLyyvOahQsXat68ea4qEwBQidHGAABKymWBKiQkRNu3b3dMJyYmKjg42DGdk5Oj2rVra/ny5ZKkPXv26Nprr82zneHDh6tfv3655sXHx2vIkCEuqhwAUFnQxgAASsplgap9+/Z67bXXlJycrCpVqmjt2rWaNm2aY7nFYtGoUaO0fPlyBQcH67333lNYWFie7fj7+8vf399VZQIAKjHaGABASblsUIqQkBCNGzdOw4YNU9++fRUeHq4WLVpo9OjR2rVrl6xWq6ZOnar7779fvXr1UvXq1XXfffe5qhwAAAAAKHUWk9/NTle4uLg4de/eXevXr1fdunXdXQ4AoAKhjQEAFIdLv9gXAAAAACoyAhUAAAAAOIlABQAAAABOIlABAAAAgJMIVAAAAADgJAIVAAAAADiJQAUAAAAATiJQAQAAAICTCFQAAAAA4CQCFQAAAAA4iUAFAAAAAE4iUAEAAACAkwhUAAAAAOAkAhUAAAAAOIlABQAAAABOIlABAAAAgJMIVAAAAADgJAIVAAAAADjJs7AVkpOTFRgYWBa1AAAA4Apw9LcvtO/beUo/kyBfvxA1bP2wrm4c6u6ygCtSoT1U4eHheuKJJ7R9+/ayqAcAAABudPS3L7T36xeUfiZeklH6mXjt/foFHf3tC3eXBlyRCg1UGzZsUPv27TV79mxFRERo0aJFOnPmTFnUBgAAgDK279t5smWn55pny07Xvm/nuaki4MpWaKDy9fXVgAEDtGzZMk2cOFHvvfeeOnXqpOeff17Hjx8vixoBAABQRtLPJBRrPlDZFWlQiq+//lqPPPKIxo0bpzvuuENLlizR1VdfrQcffNDV9QEAAKAM+fqFFGs+UNkVOijF7bffrpo1a2rw4MGaM2eOfH19JUlNmzbV0qVLL/vamJgYzZ8/X1lZWRoxYoSGDBmSa/mePXv03HPPKSsrS1dffbXmzJkjf3//EuwOAAAASqJh64e19+sXcl32Z/X0VcPWD7uxKuDKVWgP1dy5c/Xvf/9bd955p6xWa67L/NavX1/g6xISEhQdHa3Fixdr5cqVWrp0qX7//fdc60yfPl2PPvqoVq1apQYNGujdd98twa4AAACgpK5uHKobOk+Ur19tSRb5+tXWDZ0nMsofUIBCe6ji4+M1fvx4rV27VocPH9Y999yjGTNmqFu3bpd9XWxsrNq2bauAgABJUs+ePbVmzRo9/PCFv27YbDalpqZKktLS0lSjRo0820lJSVFKSkqemgAAKCnaGCB/VzcOJUABRVRooHrzzTf1/vvvS5IaNGigTz75RA899FChgSoxMVFBQUGO6eDgYO3cuTPXOuPHj9fIkSM1Y8YMValSRcuWLcuznYULF2rePEaVAQCUPtoYAEBJFRqobDabateu7Zi++uqrZbPZCt2wMSbPPIvF4nienp6uZ599VgsXLlSLFi30r3/9S1FRUXr77bdzvWb48OHq169frnnx8fF57scCAKC4aGMAACVVaKAKDAzUkiVLNHDgQFksFn3yySe66qqrCt1wSEhIri8DTkxMVHBwsGP6119/lY+Pj1q0aCFJuvvuu/XKK6/k2Y6/vz8DVQAAXII2BgBQUoUOSjF16lQtW7ZMLVq0UIsWLbRs2TJNnjy50A23b99eW7duVXJystLS0rR27Vp17tzZsfy6665TfHy8/vjjD0n2AS6aN29egl0BAAAAgLJVaA9V/fr19fHHH+vUqVPy8PCQn59fkTYcEhKicePGadiwYcrKytLAgQPVokULjR49Wo8++qiaN2+umTNnauzYsTLGqFatWpoxY0aJdwgAAAAAykqhgSo5OVmrVq1SamqqjDGy2Wz6888/9c9//rPQjUdERCgiIiLXvAULFjied+nSRV26dHGibAAAAABwv0ID1dixY+Xr66vff/9d7du3V2xsrG655ZayqA0AAAAArmiF3kN15MgRvf322+rcubOGDh2qDz/8UAcPHiyL2gAAAADgilZooDo/ol/9+vX166+/KiQkRNnZ2S4vDAAAAACudIVe8lerVi298847atmypV577TX5+fnpzJkzZVEbAAAAAFzRijRsure3t2699VbddNNNevXVV/Xkk0+WRW0AAAAAcEUrtIdq1qxZmj17tiTpqaee0lNPPeXyogAAAACgPCi0h+rnn3+WMaYsagEAAACAcqXQHqqgoCD17t1bN998s6pVq+aYP3HiRJcWBgAAAABXukIDVatWrdSqVauyqAUAAAAAypVCA9XDDz9cFnUAAAAAQLlTaKCKiIjId35MTEypFwMAAAAA5UmhgWrSpEmO51lZWVq3bp2Cg4NdWhQAAAAAlAeFBqrWrVvnmm7fvr0GDRqkBx980GVFAQAAAEB5UOiw6Zc6ceKEEhMTXVELAAAAAJQrxb6H6siRI7r77rtdVhAAAAAAlBfFuofKYrEoMDBQDRs2dGlRAAAAAFAeFHrJX7169bR69Wq1bt1atWrV0j//+U8lJSWVRW0AAAAAcEUrNFCNHz9e119/vSSpTp06at26tSZMmODywgAAAADgSldooDpx4oSGDRsmSfLx8dGIESN07NgxlxcGAAAAAFe6QgNVTk6OEhISHNNJSUkyxri0KAAAAAAoDwodlGLEiBHq27evOnXqJIvFotjYWD399NNlURsAAAAAXNEKDVQDBw7UTTfdpP/+97/y8PDQ/fffr8aNG5dFbQAAAABwRSv0kr+EhAQtWbJEI0aMUIcOHRQdHV3ke6hiYmIUFhamHj16aNGiRbmW7d27V5GRkY6fTp06KTw83Lm9AAAAAAA3KDRQRUVF5Rnl75lnnil0wwkJCYqOjtbixYu1cuVKLV26VL///rtj+Q033KCVK1dq5cqVWrJkiWrUqKEpU6Y4vycAAAAAUMYKveQvv1H+Pv3000I3HBsbq7Zt2yogIECS1LNnT61Zs0YPP/xwnnXfeust3Xbbbbr11lvzLEtJSVFKSkquefHx8YW+PwAAhaGNAQCUVKGB6vwofyEhIZKKPspfYmKigoKCHNPBwcHauXNnnvVSUlK0bNkyxcTE5LudhQsXat68eYW+HwAAxUUbAwAoqWKN8idJW7duLdIof/mFLovFkmdeTEyM7rjjDtWqVSvf7QwfPlz9+vXLNS8+Pl5DhgwptAYAAC6HNgYAUFLFHuWvXr16ev/99xUREXHZ14WEhGj79u2O6cTERAUHB+dZb926dRozZkyB2/H395e/v39hZQIAUGy0MQCAkip0UApJuvrqq5WRkaF33nlHCxcudPRWXU779u21detWJScnKy0tTWvXrlXnzp1zrWOM0Z49e9SqVSvnqgcAAAAAN7psD9Uff/yh//u//1NMTIzq1Kmj9PR0bdiwQdWrVy90wyEhIRo3bpyGDRumrKwsDRw4UC1atNDo0aP16KOPqnnz5kpOTpaXl5d8fHxKbYcAAAAAoKwUGKhGjx6tPXv2KCwsTO+//76aN2+ubt26FSlMnRcREZHn0sAFCxY4nteqVUtbtmxxomwAAAAAcL8CL/nbu3ev/vKXv6hx48aqX7++pPwHlQAAAACAyqrAQLVx40YNGDBAn332mTp27KhHH31UGRkZZVkbAAAAAFzRCgxUnp6eCg0N1QcffKAVK1YoODhY6enp+tvf/qYPP/ywLGsEAAAAgCtSkUb5a9SokSZOnKjNmzfrvvvu07Jly1xdFwAAAABc8YoUqM6rUqWK7r77bn3yySeuqgcAAAAAyo1iBSoAAAAAwAUEKgAAAABwEoEKAAAAAJxEoAIAAAAAJxGoAAAAAMBJBCoAAAAAcBKBCgAAAACcRKACAAAAACcRqAAAAADASQQqAAAAAHASgQoAAAAAnESgAgAAAAAnEagAAAAAwEkEKgAAAABwEoEKAAAAAJzk6e4CAACVV/b3Pyl79dfSiRSppr88wzrL85a/uLssAACKjEAFoFKoSB/cK8q+ZH//k7KXrZGysu0zTqTYp6VyuT8AgMrJpYEqJiZG8+fPV1ZWlkaMGKEhQ4bkWv7HH39o8uTJOnXqlIKCgjR37lzVqFHDlSUBKKaK8OG9In1wL8/7YjIyZVJSpdNnZFJSlf3xugv7cV5WtrJXf33F7wsAAOe5LFAlJCQoOjpaH3/8sby9vTVo0CC1adNGjRo1kiQZY/Tggw/q2WefVefOnfXSSy/p7bff1lNPPeWqkoAyUxFCiFR+P7yb9AyZEyn2n+RTyv786/w/uC//UiYuXpZqVaSqVc49+spS7dzzalVk8SzeadIVv3uTnSNlZMpkZCo75qv89yVmozwa15O8vSRvb1mslhK9Z1H3wxgjnU2XOZ0qk3JGSrE/2n9SZU6nSueeKyOzaG9+IqVEtQMAUJZcFqhiY2PVtm1bBQQESJJ69uypNWvW6OGHH5Yk7dmzR1WrVlXnzp0lSQ888IBSUmhEUf6V1xByKWOMsj/blP+H9882yuOmRpK3lyyWkn1wl4ofQkxaukzyKUdguvRRZ9OL9saZWcrZukPKzCp4HW8ve7A6F7TyDV7n5uXsj1PO6s25f/dL18icOCWP6+vKpGfag1F6ppSR4ZhWuj0sXVh2/nmG/Xl2TuH7knJGGVPeuDDt5Sn5eMvi7XUuZHnJ4uNtf+7jZZ9/btrinXt+zsGjsn3zvwvveyJF2UtWK2fXr7L6VbUHpZQz58JSqpSTT33eXrL4V5P8/WSpEyxrMz9Z/P3OzasmS3U/ZS74SDp1Ou9ra/oXvr8AAFwhXBaoEhMTFRQU5JgODg7Wzp07HdMHDx7UVVddpaioKP30009q0qSJJk2alGc7KSkpeYJWfHy8q8oGnGZS02Q7nKjsj/+TfwhZ8R9ZZGSp6S8F+MtSw08WDw/3FHuOyc6ROXFK5vgpmeMnL/wknZRJPillFBA0Tp1RxoSXJatVquIjS1VfyddHliq+9ukqPlIV38tPV/WVxdOzwABqjp+UNaRWvqFJ6Rm56/HylCWwhiw1/WWtd7UsNf0d05bAGsp4+d/SyXz+YFPTX76THpDJzLL3sqSmyZxNkxyP6TJn02RS06SzaTKp6dKJFNnOpEnp6ZIpwkHOzlbO6s0qMBKdCzYWX+9zjz72QOHjLatjnrfk4yP5eis7ZqOUmpZ3O1WryDO0o5SZZQ9nmVn255lZ9lCWmSWTkWV/bWambBlZ59bJLNp+5Nhkdv6qnGpVZKlezR6OggMvPPe3P+rco8XHu9BNeoZ3yf27lyQvT3mGdS5CQaWDNgYAUFIuC1TG5G2hL/5LdnZ2tr799lv9+9//VvPmzfXyyy/rxRdf1IsvvpjrNQsXLtS8efNcVSZQbMZm7KHjSKJsRxJlDtsfdTKfv7RfLD1DWYs+vzBtkf2v9wH+stSsbn8M8LeHgHPTqlalwB6gIl+SdTZd5vgJe2hKuhCabMdP2mu++P+qp6cstWrIUitA1kb1lLN9j5SWT29PVV95dmsjczZdSs+QSUuX0jLs0ydTZEvLsPcS5ddzcTFPT/s6l54vsrKVs+abCyHEx0uWmjVkCawh6/V1c4UlS01/ya/qZXvKPHt3vuwH9/O9OJaA6pev9yLGZrOHsIuCV9a7Hxe4vtcDd9lDhq+P/dHH275f1mJ+e4WHR/770q+7Uz2gxhj7ti4KX5lz/lXg+r7THin2exTkfL3uvDyWNgYAUFIuC1QhISHavn27YzoxMVHBwcGO6aCgIF133XVq3ry5JCk8PFyPPvponu0MHz5c/fr1yzUvPj4+zwAXgCuYzCyZ+CTZDideCFBHEi/03FgtsgTXkvX6a2WtEyxLnWBlffhF/pcxBVSX95i7ZE6myJw4LXMyRTqRInPytD2U7f4976Vdnp4XwlZNfynA/tyWdEK2r7fnviRr6RfK+e1P+yVZF/U2Ke2S3pzq1WSpVUPWBnVluSpA1loBstQKkKVWDam6X657byz1ri7gw/sdRfrQazKzzgWuDCkt3f54Nt1+Kdu56Zyvvi3w9d6PD7fvd1XfEl1a6IoP7har1R7k/Ko65mXV9M///p+a/vJoUt/p97pYae+LxWK5cEngRfUWtB+lzfOWv7j1UljaGABASbksULVv316vvfaakpOTVaVKFa1du1bTpk1zLG/VqpWSk5P1888/q1mzZtqwYYNuvPHGPNvx9/eXvz/X06P0FNSzY06nXuhxOhegTGLyhd4TH29Z6gTL47bmslwTbA9Qta+SxSv3fyNT0GVMvbvIGlJLCqmVb13GGPulZudD1okUe/g6F8BsP++XTp8p+PKs7ByZb3cpx8Nq77mpFSDrddfYw9JVAbIE2kNTUS7FOq+kH94dPT/+fgWuk/PjzwV+eLfWDSlyrYUpiw/unmGX7wkrtfdx8b6U1X5cCWhjAAAl5dIeqnHjxmnYsGHKysrSwIED1aJFC40ePVqPPvqomjdvrtdff10TJ05UWlqaateurdmzZ7uqHJQDrh4Zzxij7G93KefioZpPpCh78efK/mht7hHIavrLek2wrDc3lfUae8+TpWaNIo2c5mwIsVgsF3o8rq2d/z7k5MicOqPMF94qcDs+sx4v/mVkl8GH96K7Ei5hKw0VZT8AACgLFpPfzU5XuLi4OHXv3l3r169X3bp13V0OSkGegQkk+4fqu3rJ46832OefH/Us/dzoaOmZ555n2EdJu3hZRoZMmn25MjLtl5plZEi2Av65e3vJM7STfTSyq4PsI7ddwdKnvVlgr47vpAfKvqASqijDzKNioI0BABSHS7/YFygKk5ml7FUFfGSKDCEAACAASURBVLfO4s+VvWS1lGMrfEOenpLvuRHRfH3so6XVCpB8vWX19ZF8fZSzbmv+r83MkmeXW0u+M2WkIvXqSO6/jwYAAMBZBCqUKZOZZR/c4VCCzOEE2Q7FyyQkFdxzZIw8urS2h6Mq50ZHO/948TxfH1k8Cx+CPOf7PWV2s70rcUkWAADAlYFABZcxGZn2AR7i4mWLS5CJS5BJOH5hkIdqVWStW1vWGxvav1w1v+/Wqekvr/AupVZTRerZoVcHAADA/QhUKJLC7nEx6RkycQmyHU6w9z7FxcscS74wIl31arLWDZG1eWN7iKobYh8C/NxQ2JaQq8psdDSJnh0AAACUDgJVBeDqG/rzDBhx/juPftoni4y95+nYiQsv8PeT9doQWVs2k/Xac+HJ3+/yX7xahkGHnh0AAACUFgJVOZdv2Fm2RpIKDA3GGPsXwmZkymRcNBJeeuZFjxmO6ZytO/IOGJGdI/PDXpmA6rLWrS2PW26UpW6IrHVDLvudQ5dD0AEAAEB5Q6Aq57I//zr/0fGWfynb7t8uCUr24KSMzKKNmidJ3l5SZlaBi32fe7AE1QMAAADlG4GqnDHZ2TKH4mX747Bs++Okk/mMWCdJmVkyR49JPueGEfcLkMXX2z4i3vl5Pj7nHr3tw407lvnY5/l4yWK1XvY7jwAAAIDKjEB1hTNp6bLtP2z/+SNO5tBR++V6kizBgQX3INX0l8/4+0ulhoo0Mh4AAABQmghUVxhzIkW2/XGy/REn2/7DMvHH7CPlWa2y1A2RR8e/ytqgrqwN6sjiVzXvPVRSqYcdRsYDAAAA8kegcqFChxq3GZmEpFwBynFpnY+XrPXryOPmprI0qCNrvavtl+RdoqzCDgNGAAAAAHkRqFykoNH3TOJxWby97CFq/2EpLcO+vHo1Wa+vK2uX22S9vq4sVwfJ4mEt0nsRdgAAAAD3IFC5SPbnm/IdfS/nP1sl2e9/8mjR1B6erq8rS2CNy35PEwAAAIArD4GqBIwx0pmzMonJsiUel0lMlkmwP+rk6QJf5zP1YVn8qpZhpQAAAABcodIGqsLub7qYybHJJJ/MFZhsicdlEpKltPQLK3p5yhIcKMt118icTbd/Ye6lavoTpgAAAIAKolIGqgLvb8rMkked4FyBySQel0k6kfuLcKtXkzU4UNZWzewBKriWrMGBUoC/LFZL/u8hMdQ4AAAAUMFUzkC1+uv8729a/qVyzk9bLbJcVVOW4EBZb2xkfwyuZQ9QVX0LfQ+GGgcAAAAqvkoZqBxDk+fDa0RfWUJqyVIrQBZPjxK9DaPvAQAAABVb5QxUNf3zD1U1/eXRoknZ1wMAAACgXCraFx1VMJ5hnSWvS7Ik9zcBAAAAKKZK2UPF/U0AAAAASkOlDFQS9zcBAAAAKDmXXvIXExOjsLAw9ejRQ4sWLcqzfN68eeratasiIyMVGRmZ7zoAAAAAcKVyWQ9VQkKCoqOj9fHHH8vb21uDBg1SmzZt1KhRI8c6u3fv1ty5c9WqVStXlQEAAAAALuOyHqrY2Fi1bdtWAQEBqlq1qnr27Kk1a9bkWmf37t1asGCBIiIiNHXqVGVkZLiqHAAAAAAodS7roUpMTFRQUJBjOjg4WDt37nRMp6am6oYbblBUVJTq1Kmj8ePH64033tC4ceNybSclJUUpKbmHOD98+LAkKT4+3lXlAwDKodq1a8vTs+hNG20MAKCoCmpjXBaojDF55lksFsfzatWqacGCBY7pUaNG6ZlnnskTqBYuXKh58+bl+x5DhgwppWoBABXB+vXrVbdu3SKvTxsDACiqgtoYlwWqkJAQbd++3TGdmJio4OBgx/SRI0cUGxurgQMHSrIHsPwS3/Dhw9WvX79c8zIzM3Xo0CHVr19fHh4eLtqD0hEfH68hQ4Zo0aJFql27trvLKRH25cpTUfZDYl+uROVxP4pbZ3lvY4qqPP4uywrHpmAcm4JxbApWkY9NQfvjskDVvn17vfbaa0pOTlaVKlW0du1aTZs2zbHc19dXc+bMUZs2bVS3bl0tWrRIPXr0yLMdf39/+fv755l//fXXu6p0l6hdu3ax/mp6JWNfrjwVZT8k9uVKVFH2Iz8VpY0pqor8uywpjk3BODYF49gUrDIdG5cNShESEqJx48Zp2LBh6tu3r8LDw9WiRQuNHj1au3btUmBgoKZOnaoHH3xQvXr1kjFGI0eOdFU5AAAAAFDqXPrFvhEREYqIiMg17+L7pnr27KmePXu6sgQAAAAAcBmXfrEvAAAAAFRkHlOmTJni7iIqOh8fH7Vp00Y+Pj7uLqXE2JcrT0XZD4l9uRJVlP0Av8vL4dgUjGNTMI5NwSrbsbGY/MY3BwAAAAAUikv+AAAAAMBJBCoAAAAAcBKBysXmzZun3r17q3fv3po9e7a7yymxWbNmafz48e4uo0Q2bNig/v37q1evXnrhhRfcXU6JrFy50vHva9asWe4up9jOnDmj8PBwxcXFSZJiY2MVERGhv/3tb4qOjnZzdcVz6b4sXbpU4eHhioiI0IQJE5SZmenmCovm0v04b9GiRbr33nvdVBWcdfE5e8+ePRowYID69OmjMWPGKCUlxc3VudfFx2bTpk2OkYmfeOIJpaamurk69xk2bJh69+6tyMhIRUZGaseOHYqJiVFYWJh69OihRYsWubtEt8nv2EgFnzcri/yOS0X7/FsoA5fZsmWLufvuu01GRobJzMw0w4YNM2vXrnV3WU6LjY01bdq0MVFRUe4uxWkHDx40HTt2NEePHjWZmZnmnnvuMRs3bnR3WU45e/asue2228zx48dNVlaWGThwoNmyZYu7yyqyH3/80YSHh5sbb7zRHDp0yKSlpZkuXbqYgwcPmqysLDNq1Khy87u5dF/++OMP06NHD3P69Gljs9nM008/bf71r3+5u8xCXbof5/3222+mU6dOZujQoW6sDsV16Tn74vPdzJkzzdy5c91ZnltdfGxOnTpl2rZta3777TdjjDFvv/22mTZtmpsrdA+bzWY6dOhgsrKyHPPi4+NN165dzYkTJ0xqaqqJiIhwHKvKJL9jY0zB583KIr/jUtE+/xYFPVQuFBQUpPHjx8vb21teXl5q2LChjhw54u6ynHLy5ElFR0frgQcecHcpJfKf//xHYWFhql27try8vBQdHa2bb77Z3WU5JScnRzabTWlpacrOzlZ2dna5Gk1n2bJlmjx5soKDgyVJO3fu1HXXXadrr71Wnp6eioiI0Jo1a9xcZdFcui/e3t6aMmWK/Pz8ZLFY1KRJk3Lxf//S/ZCkzMxMPffcc3rsscfcWBmKK79zts1mc/S8pKWlydfX113ludWlx+bAgQO65ppr1KhRI0lS165dtW7dOneW6DZ//PGHLBaLRo8erT59+ujf//63YmNj1bZtWwUEBKhq1arq2bNnuTk3l6b8jo2U/3mzMsnvuFSkz79F5dIv9q3sGjdu7Hh+4MABrV69WkuWLHFjRc577rnnNG7cOB09etTdpZTIn3/+KS8vL9133306duyYunbtqrFjx7q7LKf4+fnpscceU2hoqHx9fdW6dWv99a9/dXdZRTZ9+vRc04mJiQoKCnJMBwcHKyEhoazLcsql+1KnTh3VqVNHkpScnKxFixZp5syZ7iitWC7dD0n65z//qQEDBqhu3bpuqAjOyu+cPX78eI0cOVIzZsxQlSpVtGzZMjdW6D6XHpv69esrPj5eP//8s5o1a6YvvvhCSUlJbq7SPVJSUtSuXTtNmTJF6enpGjZsmEJDQ/Ocm3fu3OnGKt0jv2PToEGDfM+blUlBx6VDhw6Syv/n36Kih6oM/Pbbbxo1apSioqJUv359d5dTbMuXL9fVV1+tdu3aubuUEsvJydHWrVs1Z84cLVu2TLt27dInn3zi7rKc8vPPP2vFihX66quv9M0338hqterdd991d1lOM/l8g4PFYnFDJaUnISFBw4cP14ABA9SmTRt3l1NsW7Zs0dGjRzVgwAB3l4JiyO+cnZ6ermeffVYLFy7UN998o8GDBysqKsqNVbpHfsfG399fs2bN0qRJkzRgwAAFBwfLy8vLjVW6T6tWrTR79mxVrVpVgYGBGjhwoF599dU865X3c7Mz8js2mzZtcndZbne541LeP/8WBz1ULvb999/r0Ucf1TPPPKPevXu7uxynrF69WseOHVNkZKROnTqls2fPasaMGXrmmWfcXVqxXXXVVWrXrp0CAwMlSd27d9fOnTvVv39/N1dWfN98843atWunWrVqSZL69++vxYsX6/7773dzZc4JCQnJ9VfhxMTEcn0Jxb59+zR69GgNHTpUo0aNcnc5Tvnss8/022+/KTIyUmfPnlVSUpLGjh2rl19+2d2l4TLyO2cfPnxYPj4+atGihSTp7rvv1iuvvOLmSsteQe3ZXXfdpeXLl0uyD95x7bXXurlS99i+fbuysrIcgdMYozp16lSoc7Oz8js2np58jC7ouFSEz7/F4t5buCq2I0eOmDZt2pjY2Fh3l1JqVqxYUa4Hpfjxxx9Nz549zalTp0x2drYZM2aMWbZsmbvLcsrmzZtNnz59TGpqqrHZbGbSpEnm1VdfdXdZxda1a1dz6NAhk56ebjp37mwOHDhgsrOzzX333WdWr17t7vKK5fy+nD592nTp0sV8+umn7i7JKef342L//e9/GZSiHDp/zj558qRp166d2bdvnzHGmFWrVlX63+f5Y5OTk2M6depk4uPjjc1mM48//riZP3++u8tziw0bNpi+ffua9PR0c/r0aRMREWG2b99uunbtao4fP27Onj1r+vTpY3bs2OHuUstcfsfmf//7n2N5fufNyiC/4/Ldd99VuM+/hSFau9C7776rjIwMvfjii455gwYN0j333OPGqiq3m2++Wffff78GDx6srKwsdejQodxeztSxY0f99NNP6t+/v7y8vNS8eXP9/e9/d3dZTvPx8dGLL76oRx55RBkZGerSpYt69erl7rKc8tFHHykpKUnvvfee3nvvPUlSt27dGNgBblOjRg3NnDlTY8eOlTFGtWrV0owZM9xd1hXBarVq6tSpuv/++5WZmal27drpvvvuc3dZbtG1a1ft2LFDffv2lc1m0+DBg3XLLbdo3LhxGjZsmLKysjRw4EBHT2dlkt+xadWqlbvLcrv8jsuaNWsq3edfizH53LgAAAAAACgUg1IAAAAAgJMIVAAAAADgJAIVAAAAADiJQAUAAAAATiJQAQAAAICTCFQAAAAA4CQCFQAAAAA4iUAFAAAAAE4iUAEAAACAkwhUAAAAAOAkAhUAAAAAOIlABQAAAABOIlABAAAAgJMIVAAAAADgJAIVKpy4uDg1bdpUQ4YMybNswoQJatq0qZKTk4u1zTFjxujjjz++7Drbtm1TeHh4sbZ7qXvvvVfdunVTZGSkIiMjFRYWpsmTJ+vMmTNOb/PDDz/U22+/fdl1Ro8erd9//93p9zgvNjbWUXuHDh3Utm1bx/Tq1atLvH0AKGvluU0ZP368OnXq5DgPR0REqHv37lqwYEGJtnupVq1aKS4urlS3eV7Tpk0VERHh2IfIyEg9++yzLnmvi+3cuVPPPfecy98HFYOnuwsAXMHHx0cHDhzQ4cOHVadOHUnS2bNn9f3337u5ssI9/fTT6tWrlyQpKytLL7zwgp588km9+eabTm3vnnvuKXSd0mpc27dvr5UrV0qSXnvtNZ04cYIGCUC5V57blBEjRui+++5zTB85ckRhYWHq1q2bGjZs6MbKim7hwoUKDAws0/f8/ffflZCQUKbvifKLQIUKycPDQ6GhoYqJidEDDzwgSVq7dq26d++u9957z7He0qVL9cEHH8hqteqqq67SpEmT1KBBAyUkJGj8+PFKTEzUNddco+PHjztes2/fPk2fPl0nT55UTk6O7r33Xg0cOLDAWmJjYzVr1qw885988kl16tTpsvvh5eWlCRMmqEOHDtq3b58aNmyoDRs2aP78+crKypKvr6+ioqLUqlUrZWdna86cOdq4caM8PDzUqlUrTZ48WW+99ZYj2CxevFhLliyRl5eXfHx8NHXqVDVq1EjdunXTK6+8oubNmxd4TMaPHy8/Pz/98ssvio+P1/XXX6+5c+eqWrVqRfqdxMXFaciQIWrYsKEOHz6sDz74QHFxcXrppZeUlpYmi8WiRx55RF27dpUkLV++XB9++KFsNpsCAgI0adKkctP4A6hYKkqbIknx8fGSJD8/P0nSm2++qXXr1ikjI0NpaWmKiopSjx499Nprr+nw4cM6duyYDh8+rMDAQEVHRyskJETbt2/XtGnTZLFY1Lx5c9lstkKPwfjx4+Xj46Ndu3YpKSlJoaGhCgwM1FdffaVjx47phRdeULt27Qqt/2Lbt2/X7NmzlZaWJi8vL40dO1adO3fWxx9/rI8++khpaWny8/PTBx98UGCbsn37dr344ouOfRgzZoxatGihV199VadPn9aECRM0c+bMYtWFSsgAFcyhQ4dMy5Ytza5du0xoaKhj/vDhw80vv/ximjRpYo4fP25iY2PNHXfcYY4fP26MMWbFihUmNDTU2Gw289BDD5no6GhjjDEHDhwwLVu2NCtWrDBZWVkmLCzM7N692xhjTEpKigkNDTU//PCD+e9//2t69+5dotqHDh1qvvjiizzz+/fvb1avXm32799vwsPDTXJysjHGmF9//dV06NDBpKammoULF5ohQ4aYtLQ0k5OTYx577DHzySefmFdffdU8//zzJjs729x4440mISHBGGPMJ598YpYsWWKMMaZr165m586dlz0mUVFR5u677zYZGRkmMzPT9O3b13z00UcF7sv59z3v0KFDpkmTJua7774zxhhz8uRJ87e//c0cOnTIGGNMfHy86dy5szl8+LDZtm2bGTx4sDl79qwxxpjNmzfn+l0CQFkpz21KVFSU6dixo+nTp4/p3r27ad26tXnwwQfN1q1bjTHGxMXFmXvvvdekpaUZY4z57LPPTHh4uDHGfg7v3r27OX36tDHGmDFjxphXXnnFZGRkmPbt25vY2FhjjDExMTGmSZMm5tChQ4W2IXfeeafJzMw0iYmJpkmTJub99983xhjzf//3f2bkyJH57kOTJk1MeHi46dOnj+MnKSnJJCcnm3bt2pkff/zRGGNvD1u3bm0OHjxoVqxYYW677TZH7ZdrU4YNG2Y+++wzY4wxe/fuNVOmTHHU/ve//71Exx+VBz1UqLBuuukmWa1W7d69W7Vq1VJqaqqaNGniWL5582aFhYU5LiPo37+/pk+frri4OMXGxioqKkqSdN1116lNmzaSpAMHDujgwYN65plnHNtJT0/XTz/9VGDvSUn/mihJFotFVapU0ZYtW5SYmKgRI0bkWnbw4EHH/Uu+vr6SpJdfflmS/dI7yf4X1l69emnQoEG6/fbb1aFDB0VEROR6n8sdE0nq1KmTvL29JUlNmjTRqVOnilT/eZ6enmrZsqUk6ccff9SxY8f0j3/8I9e+/PLLL/ruu+/0559/atCgQY5lp06d0smTJxUQEFCs9wSA0lBe25Tzl/ydPXtW48aNk9Vq1W233SZJqlOnjmbNmqWYmBj9+eef2rFjh1JTUx2vbd26taMn6y9/+YtOnTqlX3/9VZ6eno7epPDwcMel3YW1IV27dpWXl5eCgoJUtWpVR7316tXTyZMnCzz2+V3yt2nTJtWrV08333yzJKlx48b661//qm+//VYWi0VNmzZ11L5x48YC25TQ0FBNnTpVGzZsUPv27fX4448XWAdQEAIVKrQ+ffpo1apVCgwMVGRkZK5lxpg86xtjlJ2dLYvFkmu5p6f9v0pOTo78/f0d9wlJUlJSkqpXr64ff/wx3xouvq/IGWlpadq3b58aN26sQ4cOqV27do6wJElHjx5VcHCwo8aL67r4MgxJeumll/Trr78qNjZWCxYs0EcffaT58+fn2v9LnT8mkhxhTVKeY1QU3t7euY5lw4YNtXz5csfyhIQEBQYGatu2bYqMjNRTTz0lSbLZbEpMTFSNGjWK9X4AUJrKc5tStWpVzZ49W2FhYfrXv/6l+++/X3v27NFDDz2kESNGqEOHDrrtttv0/PPPO16T3zk/v3P/+f0prA05/we5S1/njEvbt4vfy8vLS1WrVs21bkFtyqBBg9S1a1dt2bJFmzdv1rx587Rq1Sqn60LlxCh/qNAiIyO1Zs0arV69Os9oSR07dtTq1asdozOtWLFCAQEBuu6669SpUyctXbpUkv0G3m3btkmSGjRoIB8fH0djdvToUYWHh2v37t0uqT89PV0zZsxQ586dVadOHbVt21ZbtmzRvn37JNn/QtenTx9lZGSoXbt2+uyzz5SZmSmbzaYpU6bo888/d2wrOTlZXbp0UUBAgEaMGKGxY8fql19+KfIxKW0tW7bUn3/+qe+++06StHfvXvXs2VOJiYnq0KGDPv/8cyUmJkqyj1Q4fPjwUq8BAIqjvLcpNWrUUFRUlF5//XUlJCTou+++00033aSRI0eqdevWWr9+vXJyci67jSZNmsgYo02bNkmS1q9f77haoSzbkJtvvln79+/Xzp07JUm//fabvvvuO7Vu3TrPupdrUwYNGqS9e/eqf//+mjZtmlJSUnTq1Cl5eHg4giBQGHqoUKGFhISoYcOGql69ep5LxTp06KARI0Zo+PDhstlsCgwM1FtvvSWr1arJkydrwoQJCg0NVe3atdWsWTNJ9r+uvfHGG5o+fbreeecdZWdn67HHHtMtt9ziaCBLavbs2Zo/f76sVquys7PVvn17xxCxjRs31tSpU/X444/LGCNPT0/Nnz9fVatW1aBBg3T48GH1799fxhi1bt1a9957r6MHKjAwUA8++KBGjBghX19feXh46IUXXijyMSltgYGBevXVVzV79mxlZGTIGKPZs2erTp06qlOnjkaPHq1Ro0bJYrHIz89P8+bNk8ViKfU6AKCoymObcqk+ffpo+fLlevHFF/Xss89q7dq1CgsLk5eXl9q1a6dTp05d9qs6vLy89Prrr2vKlCmaO3eubrjhBtWqVavQY1DaAgMD9corr2jatGlKT0+XxWLRzJkz1aBBA/3www+51u3UqVOBbcqTTz6pGTNm6OWXX5bVatXDDz+sunXrymaz6eWXX9Y//vEPvf7666VePyoWiynuNTsAAAAAAElc8gcAAAAATnN5oDpz5ozCw8Pz/QbtvXv3asCAAerZs6eeffZZrlUFAAAAUK64NFDt2LFD99xzjw4cOJDv8qeeekqTJk3Sl19+KWOMli1b5spyAAAAAKBUuXRQimXLlmny5Ml6+umn8yw7fPiw0tPTHd9J079/f7366qsaPHhwrvVSUlKUkpKSa15OTo7S0tLUqFGjEg25CQCo3GhjAAAl5dKWYvr06QUuS0xMVFBQkGM6KChICQkJedZbuHCh5s2bl+821q9fr7p165a8UABApUQbAwAoKbf96S2/wQXzGxJ5+PDh6tevX6558fHxGjJkiMtqAwBUDrQxAICSclugCgkJUVJSkmP62LFjCg4OzrOev7+//P39y7I0AEAlQRsDACgptw2bXqdOHfn4+Oj777+XJH366afq3Lmzu8oBAAAAgGIr80A1evRo7dq1S5L00ksvaebMmQoNDVVaWpqGDRtW1uUAAAAAgNPK5JK/DRs2OJ4vWLDA8bxZs2b66KOPyqIEAAAAACh1brvkDwAAAADKOwIVAAAAADiJQAUAAAAATiJQAQAAAICTCFQAAAAA4CQCFQAAAAA4iUAFAAAAAE4iUAEAAACAkwhUAAAAAOAkAhUAAAAAOIlABQAAAABOIlABAAAAgJMIVAAAAADgJAIVAAAAADiJQAUAAAAATiJQAQAAAICTCFQAAAAA4CQCFQAAAAA4iUAFAAAAAE4iUAEAAACAkwhUAAAAAOAkAhUAAAAAOMmlgSomJkZhYWHq0aOHFi1alGf5pk2bFBERoYiICD3xxBNKTU11ZTkAAAAAUKpcFqgSEhIUHR2txYsXa+XKlVq6dKl+//13x/KUlBSNHz9e0dHRiomJUbNmzRQdHe2qcgAAAACg1LksUMXGxqpt27YKCAhQ1apV1bNnT61Zs8ax/MCBA7rmmmvUqFEjSVLXrl21bt26PNtJSUlRXFxcrp/4+HhXlQ0AqERoYwAAJeXpqg0nJiYqKCjIMR0cHKydO3c6puvXr6/4+Hj9/PPPatasmb744gslJSXl2c7ChQs1b948V5UJAKjEaGMAACXlskBljMkzz2KxOJ77+/tr1qxZmjRpkmw2m+666y55eXnlec3w4cPVr1+/XPPi4+M1ZMiQ0i8aAFCp0MYAAErKZYEqJCRE27dvd0wnJiYqODjYMZ2Tk6PatWtr+fLlkqQ9e/bo2muvzbMdf39/+fv7u6pMAEAlRhsDACgpl91D1b59e23dulXJyclKS0vT2rVr1blzZ8dyi8WiUaNGKSEhQcYYvffeewoLC3NVOQAAAABQ6lwWqEJCQjRu3DgNGzZMffv2VXh4uFq0aKHRo0dr165dslqtmjp1qu6//3716tVL1atX13333eeqcgAAAACg1FlMfjc7XeHi4uLUvXt3rV+/XnXr1nV3OQCACoQ2BgBQHC79Yl8AAAAAqMgIVAAAAADgJAIVAAAAADiJQAUAAAAATiJQAQAAAICTCFQAAAAA4CRPdxfgLpviVmvR3teVlBavq6rU1pAb/qEudZ37YuHS2lZp1gQAAADA9SploNoUt1rzd7ygjJx0SdKxtKN648dpysrJUsc6fyvWtr45vFYLdr2oTFvGhW3teEHGGN1+be8S1TR/xwuSRKgCAAAAimnNwf2av+dHJaSdVUiVqnrwxpbqVa9Bqb9Ppfxi37//p7eOpR11QWV5WWWV1WKV1eIhi8Vif5T90XrR9KmMZNlky/P6Kp7VdFeT0QrwqaVA36tU0zdIFl5VcwAAIABJREFUAT615OflL4vFUuD7VvQeOHrzALgKX+wLuE9ZfQB293u6830rizUH92vmD9uUnpPjmOfr4aEJrdqU+nGulD1USWnxBS4b9pfHirWt9396pcBldzUZLdv/t3fvcVHV+f/AX2cuDCAhgsxglLe0MgVlU1QsTVvFREKN/amxkV3Yb5ax0W9bzKx1actruRmtra5rWpratwxxW9fS2lTIwjVR1E0zr8lFQEe5zO2c7x8zjAzMMMM4wwzwej4ePOZcZj7nfT4c5pzXnDMHSYQoiZAgWodtx00QJQlfnN1qt406Yw3WHf1zs+lKWQDCVBHoFhiBbqpIdAvsbhnvjgtXT+Ofp7fAIOoBXD8DpzPWY1T0+Fat374Ln2PNkaU2Z+DcOXPmyTNwnj6b19EDI9ev/dZERP6lMx0A+yrYND4ALq2rxcKD+wHAI8uWJAlGSYRRlGAURRglEZ+fO4PcIwehE68v8/X/7IdWr8f9t/SEQiaDXJBBIQiQywTIBRlkLXyg7Spvr2tLy+2I27AkSag1GnFZX4/LOh2qdTq8WVxkE6YAoN5kwsqS7z2+zjxD1UhkUA+sGv8Pn7TluJ0o/Pm+LajWXUJ1/SVU6ypRXV+B6vpLuKyrvD5NdwlX9ZdbVfuNECAgPDASAfJAqOQqBMhVCJAFmh/lKgTIVDbz/nX6Y9QarzVrJ0QZipl3PgVRkiBBAiyPUsNjo2FYhreeXGe3rS7KmzDzjtmQC3LIZHLIhYYfhc24TFBYHmU4fOk75P34vjV8Auaw+qvbn8RQzb0QIFjOBAqQCTLruguCAAEyCAAgCPju4tfYcDzXGjwBIECmQtqdz2BYjzHN1sFmHSUR5j9C83hR6R7874k1zWp6qP/j+IV6VKt+T/8p34ePT/y9SVsq/PrOOUiI/iUUggJymQIKmQIKQQm5TGFdz8aahlgAUMkDMXvw/BsOxP7Qlj/W1Li9jhzO/HH9eIaK7GnLT7vtLbstD4Jbu66iJEEvmmAwidCLJtvhRtP0JhGGJsM6UYTBZJ628cRx1BgNzdoPlMsxQnOzOQRZgpD50RyMTJJkO90yz2QzTULD3vZGCQDkgswSsAQoLMMKQQa5IEAuszxan2MJZI3mFVdWQC82vzIpWKHAjH53IlCuQKBcbn5UyKGSWR4dTpdDbmf/3Vh72oaNoogrep05HOnrcUWnw2W9OShd0etQrau3POpw2TJsrz/tEQB8My3NQ2tmabMzBip/PHjyRDsG0YArukpkfO74+Y8NfN7lmgBgbcmbDueNu/VB6EUd9CYd9KZ686Oog87UaJplfuMDevJvMsgglykgFxRQyJRQyBTQ6qrtXpIqFxS4OaRXq9r/+doZmCSj3bZ63nSbJaxeD7LXA6ztMAQBJ6qP2N22AmQqDI0a3ShEyyGXmcN1Q5iWWcK2XCbHP05tchj4H77zadvLdtHwevOPIMgsl/aaL+N95/scXNFXN2urm6o7/jDyL1A07ttGgbZhWuNA6+n3Kn87A+fp8OkpDFTtg6dDhihJqDUacM1gwFWDHtcMeutwjcGAd0sO4Zqdg/1ghQLJvW6DQiaDQpCZHy0H1+Zh88F0w3x5o3lye88XzOMN8/aVnsdfjhyynkEBgACZHL8ZEIPhlpBhkEwwihIMogijaBmWTJZx84/B8tMQPGzGG+ZbwsfXF89D1+STfQCQCwJ6BHeBzmRuuyEYGSXXDmRvxG2hXa/3m51+svZxo3lNfwf2+nvZoSKHy3xh8DCYJHNgM0kiTKJkDmqW4YZ5DaHOZDn7df015lDXdJ5RklBcWeHxPgqQyRAoV0AltwQvhdwazFRyOQ5UlDU7YwMAXRRKzOx3J+QyAbKG4Gc5EycXGqbJGs0THM+TNZ+3v+wi3vvvEZvAoxRkGBt9K6KCu5hDkd4cjC5bQtRVg+PjxpuUAQhTqRAWoEKYKhBhASp0U6nQNUCFbqpAy6MK2d98jYr6umavjwoKRt4DUz3T6RadMlAB/ntw4Yl2/PEMXMbnk+xeahkRqMabYz4E7BwwNz0LZJ4mw9O7Uhy0pcGbYzZClESYJBNMkhEmyQRRMsEkmizD5mkN4y8XZDisOXvYMpszZZAsn27ZnD0zf9614uArDtv5bVwOYLNe5nW6Pmy+dKBhfRd95zj0vjTc8SWm9ry23/ElrLMHz4dJNMIoGWESjTBJRhhFA4zW4evTdp75xGE7I3vc36qaCi/ucjhvmGZ08zOTdvvd/FhSecBhW9EhvS2X1Fq2B7HR9iCZrMOiaLIbFn2lcaDVmeosZzZtKWUBiOk+zO7Z4IbxxmeLf7x8FP86878wiAabNqb2m4U49chW1XewvBBbT77X7Axqct80xHQfCtFyObPU6BJn22nmy5xFmLCu5C1cM1xptgx33qs8iYHK/9n7pF0llyNz0C8Qr466HoqMBlzTmx+v6i0hqfE0S1hqeHT3gKiLQmk9E2JqJ4dVcksAUVp+GgKGUibD2WtXHb4u8dbeCJDJESCTIUAuh1ImM4/LzdOUjYbtTVPKzAf3SpnM+hggk0Mpl2HajjyU1tU2W6Y3DoAbpPxza5sv09lyP504BTrRBJ3RhHqTCTqTEfUmI+pNJtSbjNBZHuuNJut0nXW6CfVGY6Pp15/z38tVXlsfdyllMmswsheKwgJU6KpSoVtAIMIs8xUy1/7rE79D1QbG3DLJY5+AeqotT7WTNuAZu5/6pg14xmdt/XrAHLvtPHJXJkJV3TzU1rOtbisyqIfDwDiixziX2/nw+EqH7dx362SP1TRUc6/H2prQa5rL7RwsL3TYzu+HLW1VTS2F9HnDm39f0N22csc5DoFNtRT4l43eYA0EDQFNahQSmn4v8rX9v8VlXWWztkIDuuE3sXPNIdYSVk2iEQbJ0CjQNnoUjdh26gO79RpEPbT6y9CbdNCZ6t06G2wQ9djywyps+WGVy/3UUlufnFyLT06uveG2gJa/50qdmyRJOFdz1e53I3QmE5Ye+s7ha2UQEKJUootSiZuUAQhRKnFzcAhClEqEWMbN0xsPX5/36O5/osyFA2/JcmbC2ORyM/OZCdvv71x/tJ3W+PV/LCp0uE6Lh482n22Rye0GI6Xs+nDDmZuG4Za+B9TSwX7OsNZdet4aswcOsXsAPHvgkA61TGfLFQTBcmZJga4eXKazENdwVk1sOLsmieYPwJqMm8+8XZ8uNp0nNZ4nIqvgK7v1CAD2pMxo8SZrN6IhNLXF5bKdNlB1ZA2hzBNnuzzVlj/WBHguMPpjiPVkW/5YkyfbainwhwVGtKqtWQOz7Lb1+KD/j1E3t+6mMIUXdzkMjEtHv2/3NaIkwmDSQWe9HFeHZ3ZPBRx89v7KiNxW1ZTzzRyH814f9XfrZZDyJpdDNtzlVGa5y6kgCHhx7+Ooqi9v1k73oKhW1UQdl1EU8d/LVSiurMD3lRU4VFmBal19i6/549AEuyEpWKG4oQO3p1088BYEwXr5mSf8teSQw4Pg+6Jv9cgymvJVyGjLA2BfLtNXy3UW4hSC4JVgEBUUbHcb1gQFey1MNZjYs0+b3HSDgaqD6shn4DzZVkcPjFy/9lsT4F5glAkyqBRBUCHIOi0yKMphMItTJ7SqppbOeg6IaN3BVvpdmR4L19QxXDMYcKTqEg5VluNQZQVKqi5ZD/6iu4RgpKYHBkeosfpYMS45+G6Etw6efHXg7Ytw46t1bVh2W991zhfL9MVyO9M23NY67XeoiIjaA098t9Ifb8TTuD3e5a/zKqutRXFVOQ5dMp99OnnlMkRIkEHA7WHdMDgiEoO7qzE4PBLdg65/SODLu5X5Qke91TV1Hh19G3YaqKqqqhAeHt5W9biEOzsiotbxxxvx+CvuY7xDlCSc0l5GseXSvUOVFbhYWwMACJIrEBPRHYMjIhEbEYmB3bqji1LZYnsd/QCNiNoPp5f8TZ48GSNHjsTMmTMxdOjQtqiJiIg8zB8vuSXP89U/Y7W3zHqTEceqK83h6VIFDlddst4KuXtgEAZHRGJmvzsRGxGJ/l27tfo7R766TIuIqCmngWr37t34xz/+gSVLlqCurg4zZsxASkoKQkJC2qI+IiIickHTy+BK62qx8OB+APBa8LC3zJwDhVh9rBiltbXW/0/U56auuD+6p+USvkjcHBzi9S+jExG1lVZ9h2r//v2YN28eqqqqMGXKFMyZMwcREa27A5Yn8HIMIiLylva6j3F0S2QBQJDCO/egqjMa7d4/UimTWc8+xYZHoqtK5ZXlExH5A5feYb/++mt89NFHOHDgAJKTkzFt2jT8+9//xuzZs7FlyxZv10hERERO2AtTgPmG+Sm9+3llmR+ePG53ulEU8cygOK8sk4jI3zgNVPfddx+6deuGhx9+GEuXLkVgYCAA4I477sDmzZtbfG1+fj5WrlwJg8GAWbNmIS0tzWZ+SUkJXnnlFRgMBvTo0QNLly5FaGjoDawOERFR5/Ovcz85nBcVFIznYu/2ynK/vHDW4f+XISLqLJx+A/TNN9/EBx98gF/96leQyWSorKy0ztu1a5fD15WVlWH58uXYuHEj8vLysHnzZpw8edLmOa+99hoyMzOxbds29OnTB2vWrLmBVSEiIup88k//iD98V4BeITdBJZfbzPP2/3qZPXAIAtt4mURE/sZpoCotLcXUqVMBABcuXEBSUhJ2797ttOGCggKMGDECYWFhCA4ORmJiInbs2GHzHFEUUVNjvmVqXV2d9ewXEREROffJqRP403++wTB1FNaPm4R5ccMRFRQMAeYzU97+v0wTe/bBi228TCIif+P0kr93330X69evBwD06dMHW7duxdNPP41x48a1+Lry8nJERkZax9VqNYqLi22eM3fuXDz22GN4/fXXERQUZPf7WFqtFlqt1mZaaWmps7KJiIicas/7mE0nj2N58QGMiroZC4ePhkou98mtxHn7ciLq7JwGKlEUERUVZR3v0aMHRFF02rC9mwc2vkVqfX09XnrpJaxbtw6xsbFYu3YtsrOzsWrVKpvXrFu3Drm5uU6XR0RE1FrtdR/z/g8lyD3yPe67+Vb8KX4UlDK58xcREZFXOA1U4eHh2LRpE1JTUyEIArZu3Yru3bs7bVij0aCoqMg6Xl5eDrVabR3/4YcfoFKpEBsbCwCYPn063nrrrWbtPProo9ZLDhuUlpY2u8EFERFRa7W3fYwkSVhz/AhWHyvG+Ft6YcHQhFb/Q1wiIvIsp4EqJycHzz//PHJyciAIAgYOHIhly5Y5bTghIQFvv/02qqqqEBQUhJ07d+LVV1+1zu/VqxdKS0tx6tQp9O3bF7t27UJMTEyzdkJDQ3nnPyIi8or2tI+RJAnvHj2E9/5bgqSeffHS3cMhFximiIh8zWmg6t27Nz755BNcuXIFcrkcISEhLjWs0WiQlZWF9PR0GAwGpKamIjY2FhkZGcjMzERMTAwWLlyI5557DpIkISIiAq+//voNrxAREVFHI0kSVhz+DzaePI6U3v0wNy4eskaX0RMRke84DVRVVVXYtm0bampqIEkSRFHEmTNn8MYbbzhtPDk5GcnJyTbTVq9ebR0eM2YMxowZ40bZREREnYMoSVh26Dt8fOoE/t9td+D52LttvpNMRES+5TRQPffccwgMDMTJkyeRkJCAgoIC3H23d/5BIBEREV1nkkQs+s+32HbmR6T1H4BnB8UxTBER+RmnF1///PPPWLVqFUaPHo1f//rX+PDDD3H27Nm2qI2IiKjTMooicooKse3Mj3jsjkEMU0REfsppoGq4o1/v3r3xww8/QKPRwGg0er0wIiKizsooinjlu33Yce40nrprMJ4aOJhhiojITzm95C8iIgJ/+9vfMGTIELz99tsICQnBtWvX2qI2IiKiTkdvMuGlb/fi64vnkRnzC6T1H+DrkoiIqAVOz1Dl5OQgICAAQ4cOxaBBg7BixQr87ne/a4vaiIiIOpV6kxG//+ZrfH3xPH43eCjDFBFRO+D0DNXixYuxZMkSAMALL7yAF154wetFERERdTZ1RiNeKPw3iipK8WLccEzp08/XJRERkQucBqrjx49DkiReu01EROQlNQYDni/4EsWVl/DK3SMxqVdfX5dEREQuchqoIiMjkZSUhMGDB6NLly7W6fPnz/dqYURERJ3BVb0ezxV8iWPVlciJT8D4W3r7uiQiImoFp4EqLi4OcXFxbVELERFRp3JFp8Oz+3bjxyuX8Xr8vbgv+lZfl0RERK3kNFDNmTOnLeogIiLqVKrq6/Hsvl04e1WLxSNG454e0b4uiYiI3OA0UCUnJ9udnp+f7/FiiIiIOoOKulrM2bsLF2tr8EbCfYhX9/B1SURE5Cangerll1+2DhsMBnzxxRdQq9VeLYqIiKijKqutwdN7dqFKV4e3Ro1FXHeNr0siIqIb4DRQxcfH24wnJCRgxowZmD17tteKIiIi6oh+rrmGp/d8Aa1ejxWjxiEmItLXJRER0Q1yGqiaqq6uRnl5uTdqISIi6rDOXtPimT27UG804p1778eAbhG+LomIiDyg1d+h+vnnnzF9+nSvFURERNTRnNJewZw9X8AkSXjn3l/i9rBuvi6JiIg8pFXfoRIEAeHh4bjtttu8WhQREVF7tuPsT1hZ8j3K6moRHhiIOoMBQQolVo4ej76hXX1dHhEReZDM2RN69uyJzz77DPHx8YiIiMAbb7yBS5cutUVtRERE7c6Osz9h4cH9KK2rhQSgsr4etSYT0voPYJgiIuqAnAaquXPnom/fvgCA6OhoxMfH48UXX/R6YURERO3RypLvUW8yNZu+5cf/+qAaIiLyNqeBqrq6Gunp6QAAlUqFWbNmoaKiwuuFERERtUdldbWtmk5ERO2b00BlMplQVlZmHb906RIkSfJqUURERO2VJii4VdOJiKh9c3pTilmzZmHKlCm49957IQgCCgoK8Pvf/74taiMiImp3Zg8cgoUH99tc9hcol2P2wCE+rIqIiLzFaaBKTU3FoEGD8M0330Aul+PJJ59E//7926I2IiKidmdizz4AYL3LnyYoGLMHDrFOJyKijsVpoCorK8OmTZuwYMECnDp1CsuWLcMf//hHREY6/+/u+fn5WLlyJQwGA2bNmoW0tDTrvGPHjmHu3LnW8aqqKnTt2hXbt293c1WIiIj8w8SefRigiIg6CaffocrOzm52l7958+Y5bbisrAzLly/Hxo0bkZeXh82bN+PkyZPW+QMGDEBeXh7y8vKwadMmdO3aFQsWLHB/TYiIiIiIiNqY1+7yV1BQgBEjRiAsLAzBwcFITEzEjh077D73r3/9K4YNG4ahQ4e2snwiIiIiIiLfcXrJX8Nd/jQaDQDX7/JXXl5uc1mgWq1GcXFxs+dptVps2bIF+fn5dtvRarXQarU200pLS50un4iIyBnuY4iI6Ea16i5/AFBYWOjSXf7shS5BEJpNy8/Pxy9/+UtERETYbWfdunXIzc11ujwiIqLW4j6GiIhuVKvv8tezZ0+sX78eycnJLb5Oo9GgqKjIOl5eXg61Wt3seV988QX+53/+x2E7jz76KKZOnWozrbS01OYGF0RERO7gPoaIiG6U00AFAD169IBOp8PGjRtRW1uLRx55xOlrEhIS8Pbbb6OqqgpBQUHYuXMnXn31VZvnSJKEkpISxMXFOWwnNDQUoaGhrpRJRETUKtzHEBHRjWoxUJ06dQrvvfce8vPzER0djfr6euzevRs33XST04Y1Gg2ysrKQnp4Og8GA1NRUxMbGIiMjA5mZmYiJiUFVVRWUSiVUKpXHVoiIiIiIiKitOAxUGRkZKCkpwaRJk7B+/XrExMRg3LhxLoWpBsnJyc0uDVy9erV1OCIiAvv27XOjbCIiIiIiIt9zeNv0Y8eO4a677kL//v3Ru3dvAPZvKkFERERERNRZOQxUX331FR566CFs374d99xzDzIzM6HT6dqyNiIiIiIiIr/mMFApFAo88MADeP/99/Hxxx9DrVajvr4eEyZMwIcfftiWNRIREREREfklh4GqsX79+mH+/PnYs2cPnnjiCWzZssXbdREREREREfk9lwJVg6CgIEyfPh1bt271Vj1ERERERETtRqsCFREREREREV3HQEVEREREROQmBioiIiIiIiI3MVARERERERG5iYGKiIiIiIjITQxUREREREREbmKgIiIiIiIichMDFRERERERkZsYqIiIiIiIiNzEQEVEREREROQmBioiIiIiIiI3MVARERERERG5iYGKiIiIiIjITQxUREREREREbmKgIiIiIiIichMDFRERERERkZsYqIiIiIiIiNzEQEVEREREROQmrwaq/Px8TJo0CePHj8eGDRuazT916hQeeeQRPPjgg3jiiSdw5coVb5ZDRERERETkUV4LVGVlZVi+fDk2btyIvLw8bN68GSdPnrTOlyQJs2fPRkZGBrZt24YBAwZg1apV3iqHiIiIiIjI4xTearigoAAjRoxAWFgYACAxMRE7duzAnDlzAAAlJSUIDg7G6NGjAQBPPfUUtFpts3a0Wm2z6aWlpd4qm4iIOhHuY4iI6EZ5LVCVl5cjMjLSOq5Wq1FcXGwdP3v2LLp3747s7GwcPXoUt99+O15++eVm7axbtw65ubneKpOIiDox7mOIiOhGeS1QSZLUbJogCNZho9GIb7/9Fh988AFiYmLw5z//GYsWLcKiRYtsXvPoo49i6tSpNtNKS0uRlpbmncKJiKjT4D6GiIhulNcClUajQVFRkXW8vLwcarXaOh4ZGYlevXohJiYGADB58mRkZmY2ayc0NBShoaHeKpOIiDox7mOIiOhGee2mFAkJCSgsLERVVRXq6uqwc+dO6/elACAuLg5VVVU4fvw4AGD37t0YOHCgt8ohIiIiIiLyOK+eocrKykJ6ejoMBgNSU1MRGxuLjIwMZGZmIiYmBu+88w7mz5+Puro6REVFYcmSJd4qh4iIiIiIyOMEyd6Xnfzc+fPncf/992PXrl245ZZbfF0OERF1INzHEBFRa3j1H/sSERERERF1ZAxUREREREREbmKgIiIiIiIichMDFRERERERkZsYqIiIiIiIiNzEQEVEREREROQmBioiIiIiIiI3MVARERERERG5iYGKiIiIiIjITQxUREREREREbmKgIiIiIiIichMDFRERERERkZsYqIiIiIiIiNzEQEVEREREROQmBioiIiIiIiI3MVARERERERG5iYGKiIiIiIjITQxUREREREREbmKgIiIiIiIichMDFRERERERkZsYqIiIiIiIiNzEQEVEREREROQmrwaq/Px8TJo0CePHj8eGDRuazc/NzcXYsWORkpKClJQUu88hIiIiIiLyVwpvNVxWVobly5fjk08+QUBAAGbMmIHhw4ejX79+1uccOXIEb775JuLi4rxVBhERERERkdd4LVAVFBRgxIgRCAsLAwAkJiZix44dmDNnjvU5R44cwerVq3Hu3DkMGzYM2dnZUKlUNu1otVpotVqbaRcuXAAAlJaWeqt8IiJqh6KioqBQuL5r4z6GiIhc5Wgf47VAVV5ejsjISOu4Wq1GcXGxdbympgYDBgxAdnY2oqOjMXfuXPzlL39BVlaWTTvr1q1Dbm6u3WWkpaV5p3giImqXdu3ahVtuucXl53MfQ0RErnK0jxEkSZK8scB3330XdXV11oD00Ucf4fDhw8jJybH7/KNHj2LevHn49NNPbabb+/RQr9fj3Llz6N27N+RyuTfK7xBKS0uRlpaGDRs2ICoqytfl+DX2lWvYT65jX7nOk33liTNUrdnH8PfsHPvINewn17CfXMN+ck1r+6nNz1BpNBoUFRVZx8vLy6FWq63jP//8MwoKCpCamgoAkCTJboGhoaEIDQ1tNr1v375eqLpjioqKatUntp0Z+8o17CfXsa9c54u+8tQ+hr9n59hHrmE/uYb95Br2k2tutJ+8dpe/hIQEFBYWoqqqCnV1ddi5cydGjx5tnR8YGIilS5fi3LlzkCQJGzZswPjx471VDhERERERkcd5LVBpNBpkZWUhPT0dU6ZMweTJkxEbG4uMjAwcPnwY4eHhyMnJwezZszFx4kRIkoTHHnvMW+UQERERERF5nNcu+QOA5ORkJCcn20xbvXq1dTgxMRGJiYneLIGIiIiIiMhr5AsWLFjg6yLIe1QqFYYPH97sdvTUHPvKNewn17GvXNee+6o9195W2EeuYT+5hv3kGvaTazzRT167yx8REREREVFH57XvUBEREREREXV0DFRERERERERuYqDqQHJzc5GUlISkpCQsWbIEAFBQUIDk5GRMmDABy5cv93GF/mfx4sWYO3cuAODYsWN46KGHkJiYiJdeeglGo9HH1fne7t27MW3aNEycOBF/+tOfAHCbciQvL8/697d48WIA3KaaunbtGiZPnozz588DcLwttZd+y8/Px6RJkzB+/Hhs2LDB1+X4FVd/150d99uueeuttzBp0iQkJSVh7dq1ANhPjvC4pmXp6elISkpCSkoKUlJScOjQIc+8l0vUIezbt0+aPn26pNPpJL1eL6Wnp0v5+fnSmDFjpLNnz0oGg0F6/PHHpa+++srXpfqNgoICafjw4VJ2drYkSZKUlJQkHTx4UJIkSXrxxRelDRs2+LI8nzt79qx0zz33SBcvXpT0er00c+ZM6auvvuI2ZUdtba00bNgwqbKyUjIYDFJqaqq0b98+blONfP/999LkyZOlgQMHSufOnZPq6uocbkvtod9KS0ulsWPHStXV1VJNTY2UnJwsnThxwtdl+YXW/K47M+63XbN//35pxowZksFgkOrq6qSxY8dKx44dYz/ZweOalomiKI0aNUoyGAzWaZ56L+cZqg4iMjISc+fORUBAAJRKJW677TacPn0avXr1wq233gqFQoHk5GTs2LHD16X6hcuXL2P58uV46qmnAAAXLlxAfX09hgwZAgCYNm1ap++uDAbNAAAEyUlEQVSrzz//HJMmTUJUVBSUSiWWL1+OoKAgblN2mEwmiKKIuro6GI1GGI1GKBQKblONbNmyBX/4wx+gVqsBAMXFxXa3pfbyt1hQUIARI0YgLCwMwcHBSExM9Ms6fcHV33Vnx/22a+Lj47F+/XooFApUVlbCZDJBq9Wyn5rgcY1zp06dgiAIyMjIwIMPPogPPvjAY+/lXv0/VNR2+vfvbx0+ffo0PvvsMzzyyCOIjIy0Tler1SgrK/NFeX7nlVdeQVZWFi5evAgAKC8vt+mryMjITt9XZ86cgVKpxBNPPIGKigqMHTsW/fv35zZlR0hICH7729/igQceQGBgIOLj46FUKrlNNfLaa6/ZjDf9m2vYltrL36K9+ouLi31Ykf9w9Xfd2XG/7TqlUokVK1bg73//OyZOnMhtyg4e1zin1WoxcuRILFiwAPX19UhPT8cDDzzgkfdynqHqYE6cOIHHH38c2dnZ6NmzZ7P5giD4oCr/8tFHH6FHjx4YOXKkdZpk578HdPa+MplMKCwsxNKlS7FlyxYcPnzY+n2Ixjp7PwHA8ePH8fHHH+PLL7/E3r17IZPJsG/fvmbPY19d5+hvrr38LbaXOv0B+6pl3G+7JjMzE4WFhbh48SJOnz7dbH5n7ice17gmLi4OS5YsQXBwMMLDw5GamooVK1Y0e547/cQzVB3IgQMHkJmZiXnz5iEpKQnffvstLl26ZJ1fXl5uvQSjM/vss89QUVGBlJQUXLlyBbW1tRAEwaavKioqOn1fde/eHSNHjkR4eDgA4P7778eOHTsgl8utz+E2ZbZ3716MHDkSERERAMyXVqxZs4bbVAs0Go3d96em0/213zQaDYqKiqzj/FtwzNHvmrjfdsWPP/4IvV6PAQMGICgoCBMmTOC+qAke17imqKgIBoPBGjwlSUJ0dLRH/uZ4hqqDuHjxIp555hksW7YMSUlJAIDBgwfjp59+wpkzZ2AymbB9+3aMHj3ax5X63tq1a7F9+3bk5eUhMzMT48aNw8KFC6FSqXDgwAEAwKefftrp+2rs2LHYu3cvtFotTCYT9uzZg4kTJ3KbsuPOO+9EQUEBamtrIUkSdu/ejfj4eG5TLXD0/hQdHd0u+i0hIQGFhYWoqqpCXV0ddu7c6Zd1+gPui+zjfts158+fx/z586HX66HX67Fr1y7MmDGD/dQIj2tcc/XqVSxZsgQ6nQ7Xrl3D1q1bsXTpUo+8l/MMVQexZs0a6HQ6LFq0yDptxowZWLRoEZ599lnodDqMGTMGEydO9GGV/m3ZsmWYP38+ampqcNdddyE9Pd3XJfnU4MGD8eSTT+Lhhx+GwWDAqFGjMHPmTPTt25fbVBP33HMPjh49imnTpkGpVCImJga/+c1vMH78eG5TDqhUKofvT+3hb1Gj0SArKwvp6ekwGAxITU1FbGysr8vySy39rjsz7rddM2bMGBw6dAhTpkyBXC7HhAkTkJSUhPDwcPaTE+3hvbQtjR071rotiaKIhx9+GHfffbdH3ssFyd5FlkREREREROQUL/kjIiIiIiJyEwMVERERERGRmxioiIiIiIiI3MRARURERERE5CYGKiIiIiIiIjcxUBEREREREbmJgYqIiIiIiMhNDFRERERERERu+j8PAhanj1WXTwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "grid = sns.FacetGrid(accuraciesForPlots, col=\"Model\", aspect=2, ylim=(0.5, 1),\n",
    "                     col_wrap=2, sharex=False, hue=\"Model\")\n",
    "grid.map(plt.axhline, y=0, ls=\":\", c=\".5\")\n",
    "grid.map(plt.plot, 'Parameter', 'Accuracy', marker=\"o\")\n",
    "grid.set_axis_labels(\"\", \"Accuracy\")\n",
    "\n",
    "grid.savefig(\"generated/accuracies.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the kNN isn't very powerful with this type of predictions, the Naive Bayes model isn't bad but we can't tune it very much. So we will spend more effort with trying to increase the accuracy of the last two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and Variance evaluation\n",
    "We compute bias and variance by repeatedly training the models on different data samples.\n",
    "\n",
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Progress: |--------------------------------------------------| 0.0% Complete\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5236e608cab4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_leaves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    878\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "N_TESTS = 20\n",
    "\n",
    "stats = pd.DataFrame(columns=['Trees', 'Type', 'Value'])\n",
    "printProgressBar(0, 100, prefix='Progress:', suffix='Complete')\n",
    "\n",
    "for max_leaves in range(5, 101, 5):\n",
    "    y_preds = np.array([])\n",
    "    \n",
    "    for i in range(N_TESTS):\n",
    "        Xs, ys = resample(X,y, n_samples=int(0.67*len(y)) )\n",
    "\n",
    "        dt = DecisionTreeClassifier(max_leaf_nodes=max_leaves)\n",
    "        dt.fit(Xs,ys)\n",
    "\n",
    "        y_pred = dt.predict(X)\n",
    "        y_preds = np.column_stack( [y_preds, y_pred] ) if y_preds.size else y_pred\n",
    "\n",
    "    dt_bias     = (y-np.mean(y_preds,axis=1))**2\n",
    "    dt_variance = np.var(y_preds,axis=1)\n",
    "    dt_error    = (y_preds - y.reshape(-1,1))**2\n",
    "\n",
    "    stats.loc[len(stats)] = [max_leaves, 'Error', dt_error.mean()]\n",
    "    stats.loc[len(stats)] = [max_leaves, 'Bias', dt_bias.mean()]\n",
    "    stats.loc[len(stats)] = [max_leaves, 'Variance', dt_variance.mean()]\n",
    "    \n",
    "    printProgressBar(max_leaves, 100, prefix='Progress:', suffix='Complete')\n",
    "\n",
    "\n",
    "grid = sns.catplot(x='Trees', y='Value', hue='Type', kind='point', data=stats)\n",
    "grid.set_axis_labels(\"Number of Leaves\", \"\")\n",
    "\n",
    "grid.savefig(\"generated/bias-variance-DT.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results the variance seems to grow rapidly, so we can try to lower it using the bagging technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import numpy as np\n",
    "\n",
    "N_TESTS = 20\n",
    "\n",
    "stats = pd.DataFrame(columns=['Trees', 'Type', 'Value'])\n",
    "printProgressBar(0, 35, prefix='Progress:', suffix='Complete')\n",
    "\n",
    "for b_rounds in range(5, 36, 5):\n",
    "    y_preds = np.array([])\n",
    "    \n",
    "    for i in range(N_TESTS):\n",
    "        Xs, ys = resample(X,y, n_samples=int(0.67*len(y)) )\n",
    "\n",
    "        dt = BaggingClassifier(DecisionTreeClassifier(max_leaf_nodes=20), n_estimators=b_rounds)\n",
    "        dt.fit(Xs,ys)\n",
    "\n",
    "        y_pred = dt.predict(X)\n",
    "        y_preds = np.column_stack( [y_preds, y_pred] ) if y_preds.size else y_pred\n",
    "\n",
    "    dt_bias     = (y-np.mean(y_preds,axis=1))**2\n",
    "    dt_variance = np.var(y_preds,axis=1)\n",
    "    dt_error    = (y_preds - y.reshape(-1,1))**2\n",
    "\n",
    "    stats.loc[len(stats)] = [b_rounds, 'Error', dt_error.mean()]\n",
    "    stats.loc[len(stats)] = [b_rounds, 'Bias', dt_bias.mean()]\n",
    "    stats.loc[len(stats)] = [b_rounds, 'Variance', dt_variance.mean()]\n",
    "    \n",
    "    printProgressBar(b_rounds, 35, prefix='Progress:', suffix='Complete')\n",
    "\n",
    "\n",
    "grid = sns.catplot(x='Trees', y='Value', hue='Type', kind='point', data=stats)\n",
    "grid.set_axis_labels(\"Bagging Rounds\", \"\")\n",
    "\n",
    "grid.savefig(\"generated/bias-variance-DT-bagging.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "N_TESTS = 20\n",
    "\n",
    "stats = pd.DataFrame(columns=['Trees', 'Type', 'Value'])\n",
    "printProgressBar(0, 50//4+1, prefix='Progress:', suffix='Complete')\n",
    "\n",
    "for l in range(45, 100, 4):\n",
    "    y_preds = np.array([])\n",
    "    \n",
    "    for i in range(N_TESTS):\n",
    "        Xs, ys = resample(X,y, n_samples=int(0.67*len(y)) )\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=l)\n",
    "        rf.fit(Xs,ys)\n",
    "\n",
    "        y_pred = rf.predict(X)\n",
    "        y_preds = np.column_stack( [y_preds, y_pred] ) if y_preds.size else y_pred\n",
    "\n",
    "    rf_bias     = (y-np.mean(y_preds,axis=1))**2\n",
    "    rf_variance = np.var(y_preds,axis=1)\n",
    "    rf_error    = (y_preds - y.reshape(-1,1))**2\n",
    "\n",
    "    stats.loc[len(stats)] = [l, 'Error', rf_error.mean()]\n",
    "    stats.loc[len(stats)] = [l, 'Bias', rf_bias.mean()]\n",
    "    stats.loc[len(stats)] = [l, 'Variance', rf_variance.mean()]\n",
    "    \n",
    "    printProgressBar(l//4+1, 50//4+1, prefix='Progress:', suffix='Complete')\n",
    "\n",
    "\n",
    "grid = sns.catplot(x='Trees', y='Value', hue='Type', kind='point', data=stats)\n",
    "grid.set_axis_labels(\"Number of Trees\", \"\")\n",
    "\n",
    "grid.savefig(\"generated/bias-variance-RF.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further improvements\n",
    "\n",
    "We can see that Random Forest has a stable error over 30 (trees) and we can proceed with a more fine tuning. To improve Decision Tree we will try to apply the bagging technique to see the improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging applied to Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Rounds: 20 - Train Accuracy: 0.859 - Validation Accuracy: 0.854\n",
      "Bagging Rounds: 25 - Train Accuracy: 0.857 - Validation Accuracy: 0.855\n",
      "Bagging Rounds: 30 - Train Accuracy: 0.859 - Validation Accuracy: 0.854\n",
      "Bagging Rounds: 35 - Train Accuracy: 0.858 - Validation Accuracy: 0.853\n",
      "Bagging Rounds: 40 - Train Accuracy: 0.858 - Validation Accuracy: 0.855\n",
      "Bagging Rounds: 45 - Train Accuracy: 0.860 - Validation Accuracy: 0.853\n",
      "Bagging Rounds: 50 - Train Accuracy: 0.858 - Validation Accuracy: 0.853\n",
      "Best Max Leaves 40\n",
      "Test Accuracy: 0.846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for b_rounds in range(20, 51, 5):\n",
    "    dt = BaggingClassifier(DecisionTreeClassifier(max_leaf_nodes=20), n_estimators=b_rounds)\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    train_acc = accuracy_score(y_true=y_train, y_pred=dt.predict(X_train))\n",
    "    valid_acc = accuracy_score(y_true=y_valid, y_pred=dt.predict(X_valid))\n",
    "    print (\"Bagging Rounds: {:2d} - Train Accuracy: {:.3f} - Validation Accuracy: {:.3f}\".format(\n",
    "        b_rounds,  train_acc, valid_acc) )\n",
    "    \n",
    "    accuracies += [ [valid_acc, b_rounds] ]\n",
    "\n",
    "best_accuracy, best_b_rounds = max(accuracies)\n",
    "print ( \"Best Max Leaves\", best_b_rounds )\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_leaf_nodes=best_b_rounds)\n",
    "dt.fit(X_train_80,y_train_80)\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=dt.predict(X_test))\n",
    "print (\"Test Accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have improved the validation accuracy, but the test one is worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning Random Forest with Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 150, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=50,\n",
       "                                                    n_jo...\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 24, 38, 52, 66, 80,\n",
       "                                                      94, 108, 122, 136, 150,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "# Random search of parameters \n",
    "# Default 5-fold cross validation, 50 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter = 100, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 52,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulted in:\n",
    "\n",
    "{'min_samples_split': 10,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 52,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.976\n",
      "Validation Accuracy: 0.852\n",
      "Test Accuracy: 0.852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, min_samples_split=10, min_samples_leaf=1, max_features='auto', max_depth=52)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=rf.predict(X_train))\n",
    "print (\"Train Accuracy: {:.3f}\".format(train_acc))\n",
    "\n",
    "valid_acc = accuracy_score(y_true=y_valid, y_pred=rf.predict(X_valid))\n",
    "print (\"Validation Accuracy: {:.3f}\".format(valid_acc))\n",
    "\n",
    "rf.fit(X_train_80,y_train_80)\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=rf.predict(X_test))\n",
    "print (\"Test Accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our previous RF: Train Accuracy: 1.000 - Validation accuracy: 0.849 - Test accuracy: 0.844\n",
    "  The tuned one: Train Accuracy: 0.976 - Validation Accuracy: 0.852 - Test Accuracy: 0.852\n",
    "  \n",
    "We've got a little gain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
